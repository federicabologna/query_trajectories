{"clarifying_information": [{"clarifying_question1": "Are you interested specifically in how classifier-free guidance has been adapted from diffusion models to other generative frameworks, such as autoregressive language models or Flow Matching approaches in NLP tasks?", "clarifying_answer1": {"clarifying_answer": "Yes, I am especially interested in how classifier-free guidance has been adapted from diffusion models to other generative frameworks such as autoregressive language models and Flow Matching approaches in NLP tasks, including the technical implementations and the advantages or limitations observed in these adaptations."}}, {"clarifying_question2": "Do you want information on practical implementations and empirical results of classifier-free guidance in non-image NLP generation tasks, such as text generation, code synthesis, or multimodal applications involving language?", "clarifying_answer2": {"clarifying_answer": "Yes, I am interested in practical implementations and empirical results of classifier-free guidance in non-image NLP generation tasks, such as text generation, code synthesis, and multimodal applications involving language."}}, {"clarifying_question3": "Are you seeking details on specific limitations, recent extensions (like negative or contrastive guidance), or novel adaptations of classifier-free guidance that target challenges unique to NLP or text-based generative modeling?", "clarifying_answer3": {"clarifying_answer": "I am seeking details specifically on recent extensions and novel adaptations of classifier-free guidance that address challenges unique to NLP and text-based generative modeling (such as guidance for autoregressive language models, negative/contrastive guidance in text, and multimodal NLP applications), rather than just general limitations."}}], "better_query": "How has classifier-free guidance been technically implemented and empirically evaluated when adapted from diffusion models to autoregressive language models and Flow Matching approaches in NLP tasks, including its advantages and observed limitations?", "better_answer": {"sections": [{"title": "Introduction/Background", "tldr": "Classifier-free guidance (CFG) is a technique developed for diffusion models that enhances conditional generation without requiring separate classifiers. It has evolved from its origins in image generation to become a fundamental mechanism in various generative tasks, including text generation and NLP applications. (16 sources)", "text": "\nClassifier-free guidance (CFG) emerged as a transformative technique in generative modeling, first introduced by Ho (2022) to address limitations of classifier guidance in diffusion models <Paper corpusId=\"249145348\" paperTitle=\"(Ho, 2022)\" isShortName></Paper>. While classifier guidance requires training a separate classifier model alongside the diffusion model <Paper corpusId=\"234357997\" paperTitle=\"(Dhariwal et al., 2021)\" isShortName></Paper>, classifier-free guidance eliminates this requirement by jointly training conditional and unconditional variants of the same model <Paper corpusId=\"276961040\" paperTitle=\"(Zhao et al., 2025)\" isShortName></Paper>. This approach allows for a trade-off between sample quality and diversity similar to classifier guidance, but with greater computational efficiency <Paper corpusId=\"272593086\" paperTitle=\"(Kerby et al., 2024)\" isShortName></Paper>.\n\nAt its core, CFG involves training a model that can perform both conditional generation G(z, c), where c represents conditioning information, and unconditional generation G(z) <Paper corpusId=\"249926846\" paperTitle=\"(Yu et al., 2022)\" isShortName></Paper>. This dual capability is achieved by randomly dropping out the conditional information during training with a certain probability <Paper corpusId=\"271328459\" paperTitle=\"(Lan et al., 2024)\" isShortName></Paper>. During inference, the model combines predictions from both conditional and unconditional paths using a weighted average:\n\nf(x) = (1 - \u03b3)f_\u03b8(x) + \u03b3f_\u03b8(x, c)\n\nwhere \u03b3 is the guidance scale that controls the influence of the conditioning information <Paper corpusId=\"271328459\" paperTitle=\"(Lan et al., 2024)\" isShortName></Paper>. By adjusting this scale, users can prioritize either diversity (lower values) or fidelity to the conditioning (higher values) <Paper corpusId=\"259095911\" paperTitle=\"(Chang et al., 2023)\" isShortName></Paper>.\n\nCFG has proven particularly effective in image generation tasks, with GLIDE demonstrating that it yields superior results in both image photo-realism and textual alignment compared to other guidance mechanisms <Paper corpusId=\"268264822\" paperTitle=\"(Cao et al., 2024)\" isShortName></Paper>. It has become standard in state-of-the-art text-to-image diffusion models <Paper corpusId=\"268536735\" paperTitle=\"(Li et al., 2024)\" isShortName></Paper>. Beyond image generation, CFG has been successfully applied to autoregressive models for text-to-image generation, where it significantly improves output image-text alignment, especially for challenging text prompts <Paper corpusId=\"249926846\" paperTitle=\"(Yu et al., 2022)\" isShortName></Paper>.\n\nThe technique has further expanded into other domains, including trajectory generation for autonomous vehicles <Paper corpusId=\"272831727\" paperTitle=\"(Peng et al., 2024)\" isShortName></Paper> <Paper corpusId=\"257921535\" paperTitle=\"(Rempe et al., 2023)\" isShortName></Paper> <Paper corpusId=\"258298040\" paperTitle=\"(Zhu et al., 2023)\" isShortName></Paper> <Paper corpusId=\"262217065\" paperTitle=\"(Niedoba et al., 2023)\" isShortName></Paper>, hypernetworks <Paper corpusId=\"256416107\" paperTitle=\"(Nava et al., 2022)\" isShortName></Paper>, and image editing <Paper corpusId=\"257102889\" paperTitle=\"(Huang et al., 2023)\" isShortName></Paper>. In the context of natural language processing, Diffusion LM has demonstrated that diffusion models can be trained on discrete text spaces with gradient-based guidance for controlled text generation <Paper corpusId=\"268536735\" paperTitle=\"(Li et al., 2024)\" isShortName></Paper>.\n\nDespite its advantages, CFG has limitations. The most significant drawback is that the attributes used for guidance must be fixed during training, limiting flexibility for new guidance criteria post-training <Paper corpusId=\"268681777\" paperTitle=\"(Souri et al., 2024)\" isShortName></Paper> <Paper corpusId=\"272593086\" paperTitle=\"(Kerby et al., 2024)\" isShortName></Paper>. This constraint has motivated research into more adaptable guidance mechanisms that retain CFG's efficiency while addressing its limitations.", "citations": [{"id": "(Ho, 2022)", "paper": {"corpus_id": 249145348, "title": "Classifier-Free Diffusion Guidance", "year": 2022, "venue": "arXiv.org", "authors": [{"name": "Jonathan Ho", "authorId": "2126278"}], "n_citations": 3970}, "snippets": ["Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance."], "score": 0.0}, {"id": "(Dhariwal et al., 2021)", "paper": {"corpus_id": 234357997, "title": "Diffusion Models Beat GANs on Image Synthesis", "year": 2021, "venue": "Neural Information Processing Systems", "authors": [{"name": "Prafulla Dhariwal", "authorId": "6515819"}, {"name": "Alex Nichol", "authorId": "38967461"}], "n_citations": 7951}, "snippets": ["We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet 256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512. We release our code at https://github.com/openai/guided-diffusion"], "score": 0.0}, {"id": "(Zhao et al., 2025)", "paper": {"corpus_id": 276961040, "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Xiaoming Zhao", "authorId": "2144306665"}, {"name": "Alexander G. Schwing", "authorId": "2281750850"}], "n_citations": 1}, "snippets": ["Instead of solely focusing on classifier-free guidance as done in the works mentioned above, we trace back to the root of classifier-free guidance, i.e., classifier guidance (Dhariwal et al., 2021). It is classifier guidance that decomposes the conditional generation into a combination of an unconditional generation and a classifier prediction. Classifier-free guidance directly mimics this decomposition, replacing the classifier by randomly dropping conditioning information during training (Ho, 2022)."], "score": 0.96826171875}, {"id": "(Kerby et al., 2024)", "paper": {"corpus_id": 272593086, "title": "Training-Free Guidance for Discrete Diffusion Models for Molecular Generation", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Thomas Kerby", "authorId": "2243157079"}, {"name": "Kevin R. Moon", "authorId": "2243003711"}], "n_citations": 3}, "snippets": ["Classifier-free guidance addresses this issue by training a diffusion model that can condition on specific attributes, allowing for both unconditional and conditional generation (Ho, 2022). During sampling, classifier-free guidance combines the outputs of a single model, both when conditioned on specific attributes and when unconditioned, effectively guiding the generation process toward the desired attributes, similar to how a Bayes classifier influences predictions. However, the main drawback of this method is that the attributes for guidance must be fixed beforehand during training."], "score": 0.970703125}, {"id": "(Yu et al., 2022)", "paper": {"corpus_id": 249926846, "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation", "year": 2022, "venue": "Trans. Mach. Learn. Res.", "authors": [{"name": "Jiahui Yu", "authorId": "2338016295"}, {"name": "Yuanzhong Xu", "authorId": "2145139570"}, {"name": "Jing Yu Koh", "authorId": "23978705"}, {"name": "Thang Luong", "authorId": "1821711"}, {"name": "Gunjan Baid", "authorId": "1396954703"}, {"name": "Zirui Wang", "authorId": "2331539"}, {"name": "Vijay Vasudevan", "authorId": "2053781980"}, {"name": "Alexander Ku", "authorId": "31702389"}, {"name": "Yinfei Yang", "authorId": "2118771180"}, {"name": "Burcu Karagol Ayan", "authorId": "143990191"}, {"name": "Ben Hutchinson", "authorId": "2044655623"}, {"name": "Wei Han", "authorId": "143911112"}, {"name": "Zarana Parekh", "authorId": "27456119"}, {"name": "Xin Li", "authorId": "2158973314"}, {"name": "Han Zhang", "authorId": null}, {"name": "Jason Baldridge", "authorId": "1387994164"}, {"name": "Yonghui Wu", "authorId": "48607963"}], "n_citations": 1133}, "snippets": ["Classifier-free guidance [37] (CF-guidance in short) is critical in the context of improving the sample quality of diffusion models [11,12,13] without pretrained classifiers. In this setup, a generative model G is trained to be able to perform unconditional generation G(z) (where z represents random noise) and conditional generation G(z, c) (where c represents some condition, such as language descriptions). It is implemented as randomly dropping out the conditional vector (masking out or switching to a learned embedding) with some probability. During the inference process, sampling of an output I is done by using a linear combination of the unconditional and conditional predictions: \n\nClassifier-free guidance has been similarly applied in the context of autoregressive models for textto-image generation [10,38] to great effect. Make-A-Scene [10] finetunes the model by randomly replacing the text prompts with padded tokens. During inference, tokens are sampled from a linear combination of logits sampled from an unconditional model and a conditional model on a text prompt. We also apply CF-guidance in Parti, and find it has a significant improvement on the output image-text alignment, especially on challenging text prompts."], "score": 0.97900390625}, {"id": "(Lan et al., 2024)", "paper": {"corpus_id": 271328459, "title": "MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music Generation", "year": 2024, "venue": "International Society for Music Information Retrieval Conference", "authors": [{"name": "Yun-Han Lan", "authorId": "2312327383"}, {"name": "Wen-Yi Hsiao", "authorId": "37188394"}, {"name": "Hao-Chung Cheng", "authorId": "2312341186"}, {"name": "Yi-Hsuan Yang", "authorId": "2312339261"}], "n_citations": 9}, "snippets": ["Classifier-free guidance (Ho, 2022) is a technique initially developed for diffusion models in generative modeling to enhance the quality and relevance of the outputs without the need for an external classifier.This approach involves training the generative model in both a conditional and an unconditional manner, combining the output score estimates from both methods during the inference stage.The mathematical expression is as\n\nHere, \u03b3 represents the guidance scale, which adjusts the influence of the conditioning information.We perform a weighted average of f \u03b8 (x, c) and f \u03b8 (x) when sampling from the output logits."], "score": 0.947265625}, {"id": "(Chang et al., 2023)", "paper": {"corpus_id": 259095911, "title": "On the Design Fundamentals of Diffusion Models: A Survey", "year": 2023, "venue": "Pattern Recognition", "authors": [{"name": "Ziyi Chang", "authorId": "2186402069"}, {"name": "G. Koulieris", "authorId": "2872629"}, {"name": "Hubert P. H. Shum", "authorId": "1993718816"}], "n_citations": 56}, "snippets": ["To avoid the extra classifier, classifier-free guidance replaces the classifier by a mixture of unconditional model and vanilla guidance. It encourages the model in the direction of guidance and simultaneously discourages away from unconditional direction [196]. As shown in Figure 13, instead of training two models, a conditional model and an unconditional one are formulated uniformly by dropping out conditions c with a probability p [172]. The two models are learned jointly as if they were a singular conditional model [24]. In particular, classifier-free guidance is formulated as: \n\nwhere w is the weight of conditions. The weight is slightly different from its counterpart in classifier guidance. When w = 0, the classifier-free guidance becomes unconditional models without vanilla guidance. The vanilla guidance is a special case when w = 1. In this case, the unconditional model is suppressed and conditions are incorporated through vanilla guidance [38]. If w > 1, the classifier-free guidance restrains the unconditional model and prioritizes conditions further by larger weights. The score from classifier-free guidance deviates quickly away from the unconditional score, and thus, samples that better satisfy the conditions will be generated [197]."], "score": 0.97119140625}, {"id": "(Cao et al., 2024)", "paper": {"corpus_id": 268264822, "title": "Controllable Generation with Text-to-Image Diffusion Models: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Pu Cao", "authorId": "2203366502"}, {"name": "Feng Zhou", "authorId": "2273950538"}, {"name": "Qing Song", "authorId": "2273931256"}, {"name": "Lu Yang", "authorId": "39702333"}], "n_citations": 38}, "snippets": ["GLIDE additionally investigates classifier-free guidance (CFG) for comparison, which yields more preferable results in both image photo-realism and textual alignment by human evaluators and is chosen as the fundamental mechanism for text-to-image generation."], "score": 0.88037109375}, {"id": "(Li et al., 2024)", "paper": {"corpus_id": 268536735, "title": "Diffusion Model for Data-Driven Black-Box Optimization", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Zihao Li", "authorId": "2258812689"}, {"name": "Hui Yuan", "authorId": "2279340788"}, {"name": "Kaixuan Huang", "authorId": "2242535459"}, {"name": "Chengzhuo Ni", "authorId": "103688818"}, {"name": "Yinyu Ye", "authorId": "2292682601"}, {"name": "Minshuo Chen", "authorId": "2258803874"}, {"name": "Mengdi Wang", "authorId": "2258997595"}], "n_citations": 13}, "snippets": ["Classifier-free guidance [Ho and Salimans, 2022] has become a standard technique in the state-of-the-art text-to-image diffusion models [Rombach et al., 2022, Ramesh et al., 2022, Balaji et al., 2022]", "For discrete generations, Diffusion LM [Li et al., 2022] manages to train diffusion models on discrete text space with an additional embedding layer and a rounding step. The authors further show that gradients of any classifier can be incorporated to control and guide the text generation."], "score": 0.9169921875}, {"id": "(Peng et al., 2024)", "paper": {"corpus_id": 272831727, "title": "Diffusion Models for Intelligent Transportation Systems: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Mingxing Peng", "authorId": "2293615241"}, {"name": "Kehua Chen", "authorId": "2267078966"}, {"name": "Xusen Guo", "authorId": "2293665950"}, {"name": "Qiming Zhang", "authorId": "2294891908"}, {"name": "Hongliang Lu", "authorId": "2255592398"}, {"name": "Hui Zhong", "authorId": "2255501442"}, {"name": "Di Chen", "authorId": "2321889100"}, {"name": "Meixin Zhu", "authorId": "2257227452"}, {"name": "Hai Yang", "authorId": "2298579285"}], "n_citations": 4}, "snippets": ["Classifier-free-based. The classifier-free mechanism combines unconditional and conditional diffusion models, achieving a balance between fidelity and diversity without the need to train a separate classifier. Additionally, it should be noted that the conditional diffusion model can employ either a concatenation mechanism or a cross-attention mechanism. In classifier-free diffusion guidance [51], the authors jointly train a conditional and an unconditional diffusion model, setting the condition c to \u2205 for the unconditional model. Then, a weighted average of the conditional and unconditional scores is used to estimate the score function: \n\nwhere w is also a guidance scale. For many traffic-related generation tasks, researchers have employed the classifier-free guidance mechanism to regulate the diversity of the generated outputs [52], (Niedoba et al., 2023), (Rempe et al., 2023), [54], [55], (Zhu et al., 2023). This approach prevents the outputs from following the conditional guidance too closely or being constrained too tightly."], "score": 0.94140625}, {"id": "(Rempe et al., 2023)", "paper": {"corpus_id": 257921535, "title": "Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion", "year": 2023, "venue": "Computer Vision and Pattern Recognition", "authors": [{"name": "Davis Rempe", "authorId": "40084473"}, {"name": "Zhengyi Luo", "authorId": "2566332"}, {"name": "X. B. Peng", "authorId": "32200465"}, {"name": "Ye Yuan", "authorId": "145412874"}, {"name": "Kris Kitani", "authorId": "144040368"}, {"name": "Karsten Kreis", "authorId": "32113848"}, {"name": "S. Fidler", "authorId": "37895334"}, {"name": "O. Litany", "authorId": "2528439"}], "n_citations": 117}, "snippets": ["We introduce a method for generating realistic pedestrian trajectories and full-body animations that can be controlled to meet user-defined goals. We draw on recent advances in guided diffusion modeling to achieve test-time controllability of trajectories, which is normally only associated with rule-based systems. Our guided diffusion model allows users to constrain trajectories through target waypoints, speed, and specified social groups while accounting for the surrounding environment context. This trajectory diffusion model is integrated with a novel physics-based humanoid controller to form a closed-loop, full-body pedestrian animation system capable of placing large crowds in a simulated environment with varying terrains. We further propose utilizing the value function learned during RL training of the animation controller to guide diffusion to produce trajectories better suited for particular scenarios such as collision avoidance and traversing uneven terrain. Video results are available on the project page."], "score": 0.0}, {"id": "(Zhu et al., 2023)", "paper": {"corpus_id": 258298040, "title": "DiffTraj: Generating GPS Trajectory with Diffusion Probabilistic Model", "year": 2023, "venue": "Neural Information Processing Systems", "authors": [{"name": "Yuanshao Zhu", "authorId": "2051691467"}, {"name": "Yongchao Ye", "authorId": "89987905"}, {"name": "Shiyao Zhang", "authorId": "2145409015"}, {"name": "Xiangyu Zhao", "authorId": "2197532318"}, {"name": "James J. Q. Yu", "authorId": "2116508870"}], "n_citations": 45}, "snippets": ["Pervasive integration of GPS-enabled devices and data acquisition technologies has led to an exponential increase in GPS trajectory data, fostering advancements in spatial-temporal data mining research. Nonetheless, GPS trajectories contain personal geolocation information, rendering serious privacy concerns when working with raw data. A promising approach to address this issue is trajectory generation, which involves replacing original data with generated, privacy-free alternatives. Despite the potential of trajectory generation, the complex nature of human behavior and its inherent stochastic characteristics pose challenges in generating high-quality trajectories. In this work, we propose a spatial-temporal diffusion probabilistic model for trajectory generation (DiffTraj). This model effectively combines the generative abilities of diffusion models with the spatial-temporal features derived from real trajectories. The core idea is to reconstruct and synthesize geographic trajectories from white noise through a reverse trajectory denoising process. Furthermore, we propose a Trajectory UNet (Traj-UNet) deep neural network to embed conditional information and accurately estimate noise levels during the reverse process. Experiments on two real-world datasets show that DiffTraj can be intuitively applied to generate high-fidelity trajectories while retaining the original distributions. Moreover, the generated results can support downstream trajectory analysis tasks and significantly outperform other methods in terms of geo-distribution evaluations."], "score": 0.0}, {"id": "(Niedoba et al., 2023)", "paper": {"corpus_id": 262217065, "title": "A Diffusion-Model of Joint Interactive Navigation", "year": 2023, "venue": "Neural Information Processing Systems", "authors": [{"name": "Matthew Niedoba", "authorId": "41032454"}, {"name": "J. Lavington", "authorId": "104018453"}, {"name": "Yunpeng Liu", "authorId": "2242387232"}, {"name": "Vasileios Lioutas", "authorId": "3814221"}, {"name": "Justice D. Sefas", "authorId": "2167148238"}, {"name": "Xiaoxuan Liang", "authorId": "2217970852"}, {"name": "Dylan Green", "authorId": "2242251179"}, {"name": "Setareh Dabiri", "authorId": "2502496"}, {"name": "Berend Zwartsenberg", "authorId": "2242252496"}, {"name": "Adam Scibior", "authorId": "2072346802"}, {"name": "Frank Wood", "authorId": "144109143"}], "n_citations": 14}, "snippets": ["Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN - a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing."], "score": 0.0}, {"id": "(Nava et al., 2022)", "paper": {"corpus_id": 256416107, "title": "Meta-Learning via Classifier(-free) Diffusion Guidance", "year": 2022, "venue": "Trans. Mach. Learn. Res.", "authors": [{"name": "Elvis Nava", "authorId": "2129786387"}, {"name": "Seijin Kobayashi", "authorId": "51194506"}, {"name": "Yifei Yin", "authorId": "2023392128"}, {"name": "Robert K. Katzschmann", "authorId": "50191333"}, {"name": "B. Grewe", "authorId": "48117063"}], "n_citations": 6}, "snippets": ["We introduce Hypernetwork Latent Diffusion Models (HyperLDM) as a costlier but more powerful alternative to pure HyperCLIP guidance to find task-adapted networks within the latent space of a hypernetwork model (Figure 2.C). We show how combining this approach with classifier-free guidance (Ho & Salimans, 2021) improves the performance of generated base networks."], "score": 0.9423828125}, {"id": "(Huang et al., 2023)", "paper": {"corpus_id": 257102889, "title": "Region-Aware Diffusion for Zero-shot Text-driven Image Editing", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Nisha Huang", "authorId": "2186281333"}, {"name": "Fan Tang", "authorId": "1443761295"}, {"name": "Weiming Dong", "authorId": "40441149"}, {"name": "Tong-Yee Lee", "authorId": "39945992"}, {"name": "Changsheng Xu", "authorId": "2155590336"}], "n_citations": 26}, "snippets": ["Enhanced Directional Guidance. To reinforce the editing direction of the source region to follow the target text, we attempt to modify a classifier-free guidance (Ho, 2022) to strengthen cross-modal guidance. It is a strategy for guiding diffusion models without necessitating the training of a separate classifier model. Generally, classifier-free guidance offers two benefits. For starters, rather than relying on the knowledge of a separate (and perhaps smaller) categorization model, it allows a single model to leverage its experience while guiding. Second, it simplifies directing when conditioned on information that is difficult to predict using a classifier."], "score": 0.9619140625}, {"id": "(Souri et al., 2024)", "paper": {"corpus_id": 268681777, "title": "Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Hossein Souri", "authorId": "78859465"}, {"name": "Arpit Bansal", "authorId": "7364835"}, {"name": "Hamid Kazemi", "authorId": "2075283338"}, {"name": "Liam H. Fowl", "authorId": "120165773"}, {"name": "Aniruddha Saha", "authorId": "2056290221"}, {"name": "Jonas Geiping", "authorId": "2284863781"}, {"name": "Andrew Gordon Wilson", "authorId": "2264628126"}, {"name": "Rama Chellappa", "authorId": "2254122195"}, {"name": "Tom Goldstein", "authorId": "2237426712"}, {"name": "Micah Goldblum", "authorId": "121592562"}], "n_citations": 1}, "snippets": ["Initially, guidance within diffusion models was predominantly achieved through two methods: classifier guidance [Dhariwal and Nichol, 2021] and classifier-free guidance [Ho and Salimans, 2022].\n\nClassifier guidance [Dhariwal and Nichol, 2021] involves training a separate classifier, adept at handling noisy image inputs.This classifier generates a guidance signal during the diffusion process, steering the generative model toward desired outcomes.However, this method necessitates the training of a specialized classifier, often a resource-intensive task.In contrast, classifier-free guidance [Ho and Salimans, 2022] internalizes the guidance mechanism within the model's architecture.This method, while eliminating the need for an external classifier, comes with its limitation: once trained, its adaptability is restricted, unable to accommodate different classifiers or evolving guidance criteria."], "score": 0.85205078125}], "table": null}, {"title": "Technical Implementation in Autoregressive Language Models", "tldr": "Classifier-free guidance in autoregressive language models involves combining conditional and unconditional predictions during inference without requiring model retraining. It is implemented by manipulating the logit distributions, allowing for controlled text generation with adjustable guidance strength. (11 sources)", "text": "\nAdapting classifier-free guidance (CFG) from diffusion models to autoregressive language models (LLMs) has proven remarkably effective, despite the architectural differences between these model types. Unlike diffusion models which predict noise, autoregressive models predict the next token in a sequence based on previous tokens. In autoregressive language models, CFG implementation works by combining conditional and unconditional predictions during the inference process <Paper corpusId=\"249926846\" paperTitle=\"(Yu et al., 2022)\" isShortName></Paper>.\n\nThe mathematical formulation for CFG in autoregressive language models builds on the same principles as in diffusion models. Given a sequence of tokens, the model combines the logits from conditional and unconditional predictions using a guidance scale parameter \u03b3 <Paper corpusId=\"260334572\" paperTitle=\"(Kornblith et al., 2023)\" isShortName></Paper>. This can be expressed as:\n\nf(x) = (1 - \u03b3)f_\u03b8(x) + \u03b3f_\u03b8(x, c)\n\nwhere f_\u03b8(x) represents the logits from the unconditional model (typically achieved by passing zeros or null tokens in place of conditioning information) and f_\u03b8(x, c) represents the logits from the conditional model <Paper corpusId=\"271328459\" paperTitle=\"(Lan et al., 2024)\" isShortName></Paper> <Paper corpusId=\"249145348\" paperTitle=\"(Ho, 2022)\" isShortName></Paper>.\n\nA notable advantage of CFG in autoregressive language models is that it can often be implemented \"out-of-the-box\" without the need for further model training <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>. This contrasts with text-to-image models, where the model typically needs to be explicitly trained with condition dropout to support CFG. For pre-trained LLMs, the implementation often involves:\n\n1. Running the model twice in parallel: once with the conditioning prompt and once with a null or empty prompt\n2. Computing a weighted average of the resulting logit distributions\n3. Sampling the next token from this modified distribution <Paper corpusId=\"260334572\" paperTitle=\"(Kornblith et al., 2023)\" isShortName></Paper>\n\nZhang et al. expressed the CFG sampling process for language models mathematically as a modification of next-token prediction probabilities, where the likelihood of each token is adjusted based on both conditional and unconditional predictions <Paper corpusId=\"266053531\" paperTitle=\"(Zhang et al., 2023)\" isShortName></Paper>. This approach enables controllable text generation by manipulating the probability distribution from which tokens are sampled.\n\nThe guidance scale parameter \u03b3 (or \u03c9 in some formulations) is critical in controlling the degree to which generation adheres to the conditioning information <Paper corpusId=\"267069249\" paperTitle=\"(Zhou et al., 2024)\" isShortName></Paper> <Paper corpusId=\"249145348\" paperTitle=\"(Ho, 2022)\" isShortName></Paper>. Higher values of \u03b3 push the model more strongly toward the conditional direction while moving away from the unconditional prediction <Paper corpusId=\"271161847\" paperTitle=\"(Jolicoeur-Martineau et al., 2024)\" isShortName></Paper>. In practice, \u03b3 values typically need tuning based on the specific task and desired output characteristics <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\nSome implementations have further refined this approach by introducing negative prompts within the unconditional branch, effectively guiding the generation away from undesired content <Paper corpusId=\"266053531\" paperTitle=\"(Zhang et al., 2023)\" isShortName></Paper>. This capability is particularly valuable for controlling harmful or undesirable outputs in language models.\n\nThe theoretical foundation of CFG in language models draws directly from the classifier-free guidance work in diffusion models <Paper corpusId=\"273098800\" paperTitle=\"(Gandikota et al., 2024)\" isShortName></Paper> <Paper corpusId=\"249145348\" paperTitle=\"(Ho, 2022)\" isShortName></Paper>. In both cases, the approach leverages the model's own understanding of the relationships between inputs and outputs, without requiring an external classifier <Paper corpusId=\"273142392\" paperTitle=\"(Chen et al., 2024)\" isShortName></Paper> <Paper corpusId=\"234357997\" paperTitle=\"(Dhariwal et al., 2021)\" isShortName></Paper>.", "citations": [{"id": "(Yu et al., 2022)", "paper": {"corpus_id": 249926846, "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation", "year": 2022, "venue": "Trans. Mach. Learn. Res.", "authors": [{"name": "Jiahui Yu", "authorId": "2338016295"}, {"name": "Yuanzhong Xu", "authorId": "2145139570"}, {"name": "Jing Yu Koh", "authorId": "23978705"}, {"name": "Thang Luong", "authorId": "1821711"}, {"name": "Gunjan Baid", "authorId": "1396954703"}, {"name": "Zirui Wang", "authorId": "2331539"}, {"name": "Vijay Vasudevan", "authorId": "2053781980"}, {"name": "Alexander Ku", "authorId": "31702389"}, {"name": "Yinfei Yang", "authorId": "2118771180"}, {"name": "Burcu Karagol Ayan", "authorId": "143990191"}, {"name": "Ben Hutchinson", "authorId": "2044655623"}, {"name": "Wei Han", "authorId": "143911112"}, {"name": "Zarana Parekh", "authorId": "27456119"}, {"name": "Xin Li", "authorId": "2158973314"}, {"name": "Han Zhang", "authorId": null}, {"name": "Jason Baldridge", "authorId": "1387994164"}, {"name": "Yonghui Wu", "authorId": "48607963"}], "n_citations": 1133}, "snippets": ["Classifier-free guidance [37] (CF-guidance in short) is critical in the context of improving the sample quality of diffusion models [11,12,13] without pretrained classifiers. In this setup, a generative model G is trained to be able to perform unconditional generation G(z) (where z represents random noise) and conditional generation G(z, c) (where c represents some condition, such as language descriptions). It is implemented as randomly dropping out the conditional vector (masking out or switching to a learned embedding) with some probability. During the inference process, sampling of an output I is done by using a linear combination of the unconditional and conditional predictions: \n\nClassifier-free guidance has been similarly applied in the context of autoregressive models for textto-image generation [10,38] to great effect. Make-A-Scene [10] finetunes the model by randomly replacing the text prompts with padded tokens. During inference, tokens are sampled from a linear combination of logits sampled from an unconditional model and a conditional model on a text prompt. We also apply CF-guidance in Parti, and find it has a significant improvement on the output image-text alignment, especially on challenging text prompts."], "score": 0.97900390625}, {"id": "(Kornblith et al., 2023)", "paper": {"corpus_id": 260334572, "title": "Guiding image captioning models toward more specific captions", "year": 2023, "venue": "IEEE International Conference on Computer Vision", "authors": [{"name": "Simon Kornblith", "authorId": "2135550613"}, {"name": "Lala Li", "authorId": "2111917831"}, {"name": "Zirui Wang", "authorId": "2331539"}, {"name": "Thao Nguyen", "authorId": "2167669221"}], "n_citations": 15}, "snippets": ["Classifier-free guidance (CFG) (Ho, 2022) aims to generate outputs that maximize or otherwise achieve high values of \n\nwhere proportionality holds because p(x|y)/p(x) = p(y|x)/p(y) and p(y) is fixed. The parameter \u03b3 is called the guidance scale and controls the trade-off between maximization of p(x|y) and p(y|x). When \u03b3 = 1, l \u03b8,\u03b3 (x, y) = p(x|y) and guidance has no effect. Setting \u03b3 > 1 inflates the probability of the image given the caption p(y|x) relative to the unconditional probability of the caption p(x). Ho and Salimans (Ho, 2022) originally proposed CFG in the context of diffusion models, which estimate the score functions \u2207 log p(x|y) and \u2207 log p(x). Although l \u03b8,\u03b3 (x, y) factorizes autoregressively, it is not a normalized probability distribution, so it is not entirely clear how one should sample tokens when performing autoregressive generation. Crowson [8] suggested to sample from \n\nwhere f \u03b8 (x n\u22121 , . . . , x 1 , 0) are logits generated by the model without conditioning, usually by passing zeros in place of the conditioning information. This formulation has been successfully applied in autoregressive image models [12]47]. In our experiments, we adopt this formulation as well, but since we decode greedily, i.e., at each step we take the token that maximizes q\u03b8,\u03b3 (x n |x n\u22121 , . . ."], "score": 0.92578125}, {"id": "(Lan et al., 2024)", "paper": {"corpus_id": 271328459, "title": "MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music Generation", "year": 2024, "venue": "International Society for Music Information Retrieval Conference", "authors": [{"name": "Yun-Han Lan", "authorId": "2312327383"}, {"name": "Wen-Yi Hsiao", "authorId": "37188394"}, {"name": "Hao-Chung Cheng", "authorId": "2312341186"}, {"name": "Yi-Hsuan Yang", "authorId": "2312339261"}], "n_citations": 9}, "snippets": ["Classifier-free guidance (Ho, 2022) is a technique initially developed for diffusion models in generative modeling to enhance the quality and relevance of the outputs without the need for an external classifier.This approach involves training the generative model in both a conditional and an unconditional manner, combining the output score estimates from both methods during the inference stage.The mathematical expression is as\n\nHere, \u03b3 represents the guidance scale, which adjusts the influence of the conditioning information.We perform a weighted average of f \u03b8 (x, c) and f \u03b8 (x) when sampling from the output logits."], "score": 0.947265625}, {"id": "(Ho, 2022)", "paper": {"corpus_id": 249145348, "title": "Classifier-Free Diffusion Guidance", "year": 2022, "venue": "arXiv.org", "authors": [{"name": "Jonathan Ho", "authorId": "2126278"}], "n_citations": 3970}, "snippets": ["Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance."], "score": 0.0}, {"id": "(Sanchez et al., 2023)", "paper": {"corpus_id": 259308807, "title": "Stay on topic with Classifier-Free Guidance", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Guillaume Sanchez", "authorId": "2056723344"}, {"name": "Honglu Fan", "authorId": "2072838294"}, {"name": "Alexander Spangher", "authorId": "51444076"}, {"name": "Elad Levi", "authorId": "34490455"}, {"name": "Pawan Sasanka Ammanamanchi", "authorId": "1451644426"}, {"name": "Stella Biderman", "authorId": "103476203"}], "n_citations": 55}, "snippets": ["In this work, we demonstrate that CFG can be used broadly as an inference-time technique in pure language modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family models across an array of tasks: Q\\&A, reasoning, code generation, and machine translation, achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent to a model with twice the parameter-count; (3) can stack alongside other inference-time methods like Chain-of-Thought and Self-Consistency, yielding further improvements in difficult tasks; (4) can be used to increase the faithfulness and coherence of assistants in challenging form-driven and content-driven prompts: in a human evaluation we show a 75\\% preference for GPT4All using CFG over baseline.\n\nIn contrast to text-to-vision, CFG in autoregressive language modeling works out-of-the-box, without the need to further train the model.\n\nOur work also integrates into a growing body of inference techniques aimed at perturbing the logit distributions of an LM [45]73]. We demonstrate that by doubling the inference FLOP using CFG brings performances of a model about twice the size. This allows training smaller models, which can be ran on smaller hardware, and are cheaper to train.\n\nOur work faces the following limitations: CFG requires tweaking and exploration: \u03b3 values that might work in one context (i.e. long-form generation) might be poorly suited for another context."], "score": 0.95947265625}, {"id": "(Zhang et al., 2023)", "paper": {"corpus_id": 266053531, "title": "Prompt Highlighter: Interactive Control for Multi-Modal LLMs", "year": 2023, "venue": "Computer Vision and Pattern Recognition", "authors": [{"name": "Yuechen Zhang", "authorId": "2145915052"}, {"name": "Shengju Qian", "authorId": "152230789"}, {"name": "Bohao Peng", "authorId": "2272493196"}, {"name": "Shu Liu", "authorId": "25059098"}, {"name": "Jiaya Jia", "authorId": "2273012826"}], "n_citations": 24}, "snippets": ["Classifier-Free Guidance (CFG) [20] enables a control on Diffusion Models' generation process without a conven-  tional classifier. Specifically, CFG's step-wise sampling allows users to employ a negative prompt within the unconditional branch, effectively guiding the generation away from harmful distributions. This approach has been extended to language models by LLM-CFG [21], allowing a controllable text generation and improved performance. However, LLM-CFG still requires a pair-wise prompt design and does not support partial token-level reweighting within the context, which is vital for controlling VLM's generation.\n\nIn conditioned Diffusion Models [42], given a noisy image x and a class condition c, the model predicts probability likelihood P, for the conditioned step-wise sample, P\u0398 (x|c) \u221d P \u0398 (x) \u2022 P \u03a6 (c|x) \u03b3 . Here, P \u03a6 is a classifier, and \u03b3 is the guidance strength controlling the weight of likelihood on c. Ho et al. [20] observed that guidance can be offered without a classifier. Applying the Bayes rule, P \u0398 (c|x) \u221d P \u0398 (x|c)/P \u0398 (x), the sampling process of the Classifier-Free Guidance (CFG) can be expressed as \n\nLLM-CFG [21] extended this property to autoregressive language models. Given a sequence of N tokens x = {x 1 , . . . , x N }, the likelihood of predicting the entire sequence can be expressed as \n\nThe model samples each subsequent token from the conditional probability distribution. Based on Eq. ( 1), the CFG sampling on the language model can be denoted as \n\nSimilar to the transaction from Eq. (1) to Eq. ( 2), the likelihood in LLM is represented as the next-token classification probability. Thus next token's logit prediction \n\nThe formulation in Eqs. (3) and (4) offers a paradigm for controllable generation in LLMs [21], with the guidance strength \u03b3 controls the degree of generation focus. Notably, the effectiveness of this guidance depends on the careful design of the conditional prompt c, which should be naturally formed as a complete phrase or sentence to retain its semantic meaning."], "score": 0.96142578125}, {"id": "(Zhou et al., 2024)", "paper": {"corpus_id": 267069249, "title": "UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures", "year": 2024, "venue": "Computer Vision and Pattern Recognition", "authors": [{"name": "Mingyuan Zhou", "authorId": "2152175923"}, {"name": "Rakib Hyder", "authorId": "12212948"}, {"name": "Ziwei Xuan", "authorId": "2119019"}, {"name": "Guo-Jun Qi", "authorId": "2268757799"}], "n_citations": 6}, "snippets": ["Ho et al. [33] introduce the classifier-free guidance technique, blending both conditioned noise prediction \u03f5 \u03b8 (z t , t, \u03c4 (y)) and unconditioned noise prediction \u03f5 \u03b8 (z t , t, \u2205), to extrapolate one from another, \u03b5\u03b8 (z t , t, \u03c4 (y)) = \u03c9\u03f5 \u03b8 (z t , t, \u03c4 (y)) + (1 \u2212 \u03c9)\u03f5 \u03b8 (z t , t, \u2205). \n\n(\n\nwhere \u2205 is the embedding of a null text and \u03c9 is the guidance scale."], "score": 0.92626953125}, {"id": "(Jolicoeur-Martineau et al., 2024)", "paper": {"corpus_id": 271161847, "title": "Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Alexia Jolicoeur-Martineau", "authorId": "2303409806"}, {"name": "A. Baratin", "authorId": "14398916"}, {"name": "Kisoo Kwon", "authorId": "2311115257"}, {"name": "Boris Knyazev", "authorId": "49934559"}, {"name": "Yan Zhang", "authorId": "49889702"}], "n_citations": 1}, "snippets": ["To enforce better conditioning of the properties, we use classifier-free guidance, originally designed for diffusion models (Ho & Salimans, 2022), and found beneficial for autoregressive language models as well (Sanchez et al., 2023). This technique involves directing the model more toward the conditional model's direction while pushing it away from the unconditional model's direction by an equal amount. Figure 2 illustrates this concept. The amount of guidance typically requires hyperparameter-tuning. However, for simplicity and generality, in all analyses, we arbitrarily set the guidance parameter w to 1.5, where w = 1 means no guidance. Practitioners can tune the guidance for further performance gain."], "score": 0.92578125}, {"id": "(Gandikota et al., 2024)", "paper": {"corpus_id": 273098800, "title": "Erasing Conceptual Knowledge from Language Models", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Rohit Gandikota", "authorId": "52017367"}, {"name": "Sheridan Feucht", "authorId": "2140009998"}, {"name": "Samuel Marks", "authorId": "2225941937"}, {"name": "David Bau", "authorId": "2284996653"}], "n_citations": 11}, "snippets": ["This approach requires no external classifier -we leverage the model's own understanding of concept relationships as encoded in its next-token predictions. Our perspective is inspired by the classifier-free guidance work (Ho & Salimans, 2022) in diffusion model research which has later been adopted to language models (Sanchez et al., 2023)."], "score": 0.921875}, {"id": "(Chen et al., 2024)", "paper": {"corpus_id": 273142392, "title": "Opportunities and challenges of diffusion models for generative AI", "year": 2024, "venue": "National Science Review", "authors": [{"name": "Minshuo Chen", "authorId": "2258803874"}, {"name": "Song Mei", "authorId": "2295990628"}, {"name": "Jianqing Fan", "authorId": "2296663941"}, {"name": "Mengdi Wang", "authorId": "2258997595"}], "n_citations": 13}, "snippets": ["Practical implementations of conditional score estimation, such as classifier and classifier-free guidance methods, build upon ( 19 ) for reduced computational cost or better performance [47 ,104 ]. We begin with the classifier guidance method (Dhariwal et al., 2021) which is arguably the first method to allow conditional generation in diffusion models similar to GANs or flow models [105 ,106 ]. Specifically when conditional information y is discrete, e.g. image categories, the conditional score \u2207 log p t (x t | y ) is rewritten via Bayes' rule as \n\nwhere c t is the likelihood function of an external classifier. In other words, classifier guidance combines the unconditional score function with the gradient of an external classifier. The external classifier is trained using the diffused data points in the forward process. As a result, the performance of classifier guidance methods is sometimes limited, since it is difficult to train the external classifier with highly corrupted data. Later, classifier-free guidance proposes to remove the external classifier, circumventing the limitation caused by classifier training. The idea of classifierfree guidance is to introduce a mask signal to randomly ignore y and unify the learning of conditional and unconditional scores. Specifically, let \u03c4 \u2208 {\u2205 , id } be a mask signal, where \u2205 means to ignore the conditional information y and id to keep y with id y = y . For \u03c4 = \u2205 , we have \n\nand, for \u03c4 = id , we have \n\nNote that ( 21 ) coincides with ( 19 ), and recall that t 0 is an early stopping time. Combining the two cases, the classifier-free guidance method minimizes the loss function min \n\nwhere s (x t , \u03c4 y, t ) denotes a unified score network, i.e. s (x t , \u03c4 y, t ) = s (x t , t ) when \u03c4 = \u2205 and s (x t , \u03c4 y, t ) = s (x t , y, t ) when \u03c4 = id . Here \u03c4 is randomly chosen among \u2205 and id following distribution P \u03c4 . The simplistic choice on P \u03c4 is a uniform distribution on {\u2205 , id } , while it is preferred to bias towards setting \u03c4 = id more often in some applications [47 ]."], "score": 0.96533203125}, {"id": "(Dhariwal et al., 2021)", "paper": {"corpus_id": 234357997, "title": "Diffusion Models Beat GANs on Image Synthesis", "year": 2021, "venue": "Neural Information Processing Systems", "authors": [{"name": "Prafulla Dhariwal", "authorId": "6515819"}, {"name": "Alex Nichol", "authorId": "38967461"}], "n_citations": 7951}, "snippets": ["We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet 256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512. We release our code at https://github.com/openai/guided-diffusion"], "score": 0.0}], "table": null}, {"title": "Technical Implementation in Flow Matching Approaches", "tldr": "Classifier-free guidance has been adapted for flow matching models by jointly training conditional and unconditional vector fields through condition dropout during training. During inference, these vector fields are linearly combined using a guidance scale parameter to enhance sample quality and controllability in various sequence generation tasks. (7 sources)", "text": "\nFlow matching approaches represent an alternative framework to diffusion models and autoregressive models for generative tasks in NLP. The implementation of classifier-free guidance (CFG) in flow matching models follows similar principles to those used in diffusion models but operates on vector fields rather than score functions <Paper corpusId=\"276928343\" paperTitle=\"(Tuo et al., 2025)\" isShortName></Paper>. \n\nIn flow matching models, CFG is implemented by training models that can generate both conditional vector fields (when provided with conditioning information) and unconditional vector fields (when conditioning is masked or removed). This is typically achieved by randomly dropping out the conditioning information during training with a probability p_drop <Paper corpusId=\"276409208\" paperTitle=\"(Wang et al., 2025)\" isShortName></Paper>. This dual training enables the model to learn two distinct vector fields for the same data distribution.\n\nDuring inference, the guided vector field is computed through linear blending of the conditional and unconditional vector fields:\n\nv_*(x, t, c; w) = v_*(x, t, \u2205) + w \u00b7 (v_*(x, t, c) - v_*(x, t, \u2205))\n\nwhere v_* represents the vector field, c indicates the full conditioning information, \u2205 represents the masked or reduced conditioning state, and w is the guidance scale parameter <Paper corpusId=\"276409208\" paperTitle=\"(Wang et al., 2025)\" isShortName></Paper>. This formulation is analogous to the weighted score approach used in diffusion models, where the guidance scale w (or \u03c9 in some formulations) controls the degree of conditioning influence <Paper corpusId=\"276249479\" paperTitle=\"(Song et al., 2025)\" isShortName></Paper>.\n\nThe theoretical foundation for CFG in flow matching builds on an important relationship between flow fields and score functions. Tuo et al. demonstrated that a linear relationship exists between the score function and the Dirichlet flow (the marginal velocity field), allowing CFG techniques from diffusion models to be directly applied to flow matching approaches <Paper corpusId=\"276928343\" paperTitle=\"(Tuo et al., 2025)\" isShortName></Paper>. Similarly, Stark et al. derived a connection between mixture scores and flow vector fields that enables both classifier and classifier-free guidance in flow matching models <Paper corpusId=\"267547708\" paperTitle=\"(Stark et al., 2024)\" isShortName></Paper>.\n\nFlow matching with CFG has been particularly valuable for sequence generation tasks. Stark et al. introduced \"distilled Dirichlet flow matching,\" which enables one-step sequence generation with minimal performance degradation, resulting in significant speedups compared to autoregressive models while maintaining the benefits of CFG for improving generation quality <Paper corpusId=\"267547708\" paperTitle=\"(Stark et al., 2024)\" isShortName></Paper>. This approach has been successfully applied to DNA sequence generation with specific design targets.\n\nIn the context of speech synthesis, Wang et al. implemented CFG in their FELLE system through joint training of coarse and fine flow matching models using both conditional and unconditional objectives <Paper corpusId=\"276409208\" paperTitle=\"(Wang et al., 2025)\" isShortName></Paper>. Their implementation randomly masks the speech prompt during training to enable dual vector field learning.\n\nHowever, CFG in flow matching models can face challenges when the learned velocity fails to accurately capture the dataset's distribution. Fan et al. observed that when a model is underfitted, the conditional and unconditional predictions during sampling can create a mismatch, causing CFG to guide samples in directions that deviate from optimal trajectories <Paper corpusId=\"277510202\" paperTitle=\"(Fan et al., 2025)\" isShortName></Paper>. This suggests that in some cases, modified CFG implementations might be needed to achieve optimal results.\n\nThe implementation of CFG in flow matching approaches builds upon the established techniques from diffusion models <Paper corpusId=\"267750410\" paperTitle=\"(Wang et al., 2024)\" isShortName></Paper> <Paper corpusId=\"234357997\" paperTitle=\"(Dhariwal et al., 2021)\" isShortName></Paper>, adapting them to the continuous flow framework while maintaining the core principle of linearly combining conditional and unconditional predictions to enhance generation quality and controllability.", "citations": [{"id": "(Tuo et al., 2025)", "paper": {"corpus_id": 276928343, "title": "Flow Matching for Discrete Systems: Efficient Free Energy Sampling Across Lattice Sizes and Temperatures", "year": 2025, "venue": "", "authors": [{"name": "Ping Tuo", "authorId": "2349541183"}, {"name": "ZeZhu Zeng", "authorId": "2351208777"}, {"name": "Jiale Chen", "authorId": "2349541600"}, {"name": "Bingqing Cheng", "authorId": "2313482115"}], "n_citations": 0}, "snippets": ["To remove the need for a separate classifier model, Ho and Salimans [38] introduced classifier-free guidance, which linearly combines unconditional and conditional score models: \n\nIt can be shown that this formulation implicitly corresponds to a classifier P (c | x) = P (x, c; t) P (x; t). Substituting this implicit classifier back into Eq. ( 11) leads to \n\nwhich closely matches Eq. ( 12). Thus, classifier-free guidance implicitly steers the generative process by shifting the balance between conditional and unconditional scores, thereby increasing the likelihood of the desired class c without a separate classifier. In the context of flow matching, one can further show (see Appendix B) that a linear relationship exists between the score and the Dirichlet flow (i.e. the marginal velocity field in Eq. ( 6))."], "score": 0.97802734375}, {"id": "(Wang et al., 2025)", "paper": {"corpus_id": 276409208, "title": "FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Hui Wang", "authorId": "2337542688"}, {"name": "Shujie Liu", "authorId": "2334437685"}, {"name": "Lingwei Meng", "authorId": "2308630482"}, {"name": "Jinyu Li", "authorId": "2280887661"}, {"name": "Yifan Yang", "authorId": "2135622500"}, {"name": "Shiwan Zhao", "authorId": "2275765829"}, {"name": "Haiyang Sun", "authorId": "2338021437"}, {"name": "Yanqing Liu", "authorId": "2290439718"}, {"name": "Haoqin Sun", "authorId": "2275584632"}, {"name": "Jiaming Zhou", "authorId": "2275780366"}, {"name": "Yan Lu", "authorId": "2337241715"}, {"name": "Yong Qin", "authorId": "2275736194"}], "n_citations": 2}, "snippets": ["Classifier-free guidance (CFG) is a powerful technique to enhance the quality and controllability of generated outputs in flow matching and diffusion models [Ho andSalimans, 2022, Nichol and(Nichol et al., 2021). In FELLE, we implement CFG through joint training of coarse and fine flow matching models using both conditional and unconditional objectives. During training, we randomly mask the speech prompt with probability p drop for unconditional learning, which enables each model to learn dual vector fields. At inference, guided vector fields are computed through linear blending: \n\nwhere * \u2208 {c, f } denotes the model stage, c represents the full conditions, c indicates the reduced conditioning state where the speaker prompt is masked, and w represents the guidance scale."], "score": 0.96484375}, {"id": "(Song et al., 2025)", "paper": {"corpus_id": 276249479, "title": "History-Guided Video Diffusion", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Kiwhan Song", "authorId": "2345339612"}, {"name": "Boyuan Chen", "authorId": "8786274"}, {"name": "Max Simchowitz", "authorId": "2243186471"}, {"name": "Yilun Du", "authorId": "2344972384"}, {"name": "Russ Tedrake", "authorId": "2263905014"}, {"name": "Vincent Sitzmann", "authorId": "2280906248"}], "n_citations": 18}, "snippets": ["Classifier-free guidance (CFG) (Ho & Salimans, 2022) is a crucial technique for improving sample quality in diffusion models. CFG jointly trains conditional and unconditional models s \u03b8 (x, c, k) \u2248 \u2207 log p k (x k |c) and s \u03b8 (x, \u2205, k) \u2248 \u2207 log p k (x k ) by randomly dropping out the conditioning c. During sampling, the true conditional score \u2207 log p k (x k |c) is replaced with the weighted score \n\nwhere \u03c9 \u2265 1 is the guidance scale that pushes the sample towards the conditioning."], "score": 0.90576171875}, {"id": "(Stark et al., 2024)", "paper": {"corpus_id": 267547708, "title": "Dirichlet Flow Matching with Applications to DNA Sequence Design", "year": 2024, "venue": "International Conference on Machine Learning", "authors": [{"name": "Hannes St\u00e4rk", "authorId": "2124211700"}, {"name": "Bowen Jing", "authorId": "2064253810"}, {"name": "Chenyu Wang", "authorId": "2283429637"}, {"name": "Gabriele Corso", "authorId": "1630330616"}, {"name": "Bonnie Berger", "authorId": "2271178326"}, {"name": "R. Barzilay", "authorId": "2254308896"}, {"name": "T. Jaakkola", "authorId": "35132120"}], "n_citations": 58}, "snippets": ["In this framework, we derive a connection between the mixtures' scores and the flow's vector field that allows for classifier and classifier-free guidance. Further, we provide distilled Dirichlet flow matching, which enables one-step sequence generation with minimal performance hits, resulting in $O(L)$ speedups compared to autoregressive models", "we show that our classifier-free guidance approach improves unconditional generation and is effective for generating DNA that satisfies design targets."], "score": 0.904296875}, {"id": "(Fan et al., 2025)", "paper": {"corpus_id": 277510202, "title": "CFG-Zero*: Improved Classifier-Free Guidance for Flow Matching Models", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Weichen Fan", "authorId": "2340406432"}, {"name": "Amber Yijia Zheng", "authorId": "2323508574"}, {"name": "Raymond A. Yeh", "authorId": "2240073241"}, {"name": "Ziwei Liu", "authorId": "2324070583"}], "n_citations": 2}, "snippets": ["Next, classifier-free guidance (CFG) [9]44] is a widely used technique in flow matching models to improve sample quality and controllability during generation. In textto-image tasks, CFG improves the alignment between generated images and input text prompts. In other words, CFG is used because the conditional distribution induced by the learned conditional velocity does not fully match with the user's \"intended\" conditional distribution; see example in Fig. 2. We hypothesize that this mismatch arises from two fundamental factors. First, it may be from dataset limitations, where the user's interpretation of a text prompt and its corresponding image differs from the dataset distribution. Second, it could result from a learning limitation, where the learned velocity fails to accurately capture the dataset's distribution. In this work, we focus on the latter issue. When the model is underfitted, a mismatch exists between the conditional and unconditional predictions during sampling, causing CFG to guide the sample in a direction that deviates significantly from the optimal trajectory. Specifically, the velocity estimated by CFG in the first step at x 0 may contradict the optimal velocity. This suggests that skipping this prediction could lead to better results."], "score": 0.97607421875}, {"id": "(Wang et al., 2024)", "paper": {"corpus_id": 267750410, "title": "Text2Data: Low-Resource Data Generation with Textual Control", "year": 2024, "venue": "AAAI Conference on Artificial Intelligence", "authors": [{"name": "Shiyu Wang", "authorId": "2284725554"}, {"name": "Yihao Feng", "authorId": "2284730919"}, {"name": "Tian Lan", "authorId": "2284685690"}, {"name": "Ning Yu", "authorId": "2211974297"}, {"name": "Yu Bai", "authorId": "2284676271"}, {"name": "Ran Xu", "authorId": "2279097262"}, {"name": "Huan Wang", "authorId": "2258793468"}, {"name": "Caiming Xiong", "authorId": "2256976968"}, {"name": "Silvio Savarese", "authorId": "2238207181"}], "n_citations": 0}, "snippets": ["Diffusion models, notably divided into classifierguided (Dhariwal et al., 2021) and classifier-free (Ho & Salimans, 2022) categories, have significantly impacted data generation across various domains. (Hoogeboom et al., 2022)Yang et al., 2023;Ho et al., 2022;(Voleti et al., 2022). The classifier-guided diffusion guides the model during inference phase by independently training a classifier and supervising the model with its gradient, which is inefficient when computing gradient at each time step and sometimes the generation quality is deficient as the guidance is not involved in the training. By contrast, classifier-free diffusion guidance blends score estimates from both a conditional diffusion model and an unconditional one with time step as a parameter, exemplified by E(3) Equivariant Diffusion Model (EDM) (Hoogeboom et al., 2022) and Motion Diffusion Model (MDM) (Tevet et al., 2022) for controllable molecule and motion generation, respectively."], "score": 0.88037109375}, {"id": "(Dhariwal et al., 2021)", "paper": {"corpus_id": 234357997, "title": "Diffusion Models Beat GANs on Image Synthesis", "year": 2021, "venue": "Neural Information Processing Systems", "authors": [{"name": "Prafulla Dhariwal", "authorId": "6515819"}, {"name": "Alex Nichol", "authorId": "38967461"}], "n_citations": 7951}, "snippets": ["We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet 256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512. We release our code at https://github.com/openai/guided-diffusion"], "score": 0.0}], "table": null}, {"title": "Empirical Evaluation and Performance", "tldr": "Empirical evaluations of classifier-free guidance in NLP tasks have shown mixed but generally positive results, with significant improvements in question answering, reasoning, and translation tasks. Performance gains are task-dependent, with guidance strength requiring careful tuning and sometimes equivalent to using models with twice the parameter count. (7 sources)", "text": "\nThe empirical evaluation of classifier-free guidance (CFG) in language models has revealed varying degrees of effectiveness across different NLP tasks and model architectures. Sanchez et al. demonstrated that CFG substantially improves the performance of Pythia, GPT-2, and LLaMA-family models across a wide range of tasks including question answering, reasoning, code generation, and machine translation <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>. Their work showed that CFG enabled LLaMA-7B to achieve state-of-the-art performance on the LAMBADA benchmark, outperforming even PaLM-540B, which has significantly more parameters <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\nOne of the most striking findings is that CFG can provide performance improvements equivalent to using a model with twice the parameter count, effectively doubling inference efficiency while maintaining comparable quality <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>. This allows for training smaller models that can run on more modest hardware while achieving results comparable to larger models. Additionally, CFG has been shown to stack effectively with other inference-time techniques like Chain-of-Thought and Self-Consistency, yielding further improvements on difficult tasks <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\nIn speech translation tasks, CFG has demonstrated consistent benefits. Tan et al. found that non-autoregressive transformer models trained with CFG improved translation quality regardless of whether they used original or normalized speech units <Paper corpusId=\"269983348\" paperTitle=\"(Tan et al., 2024)\" isShortName></Paper>. Interestingly, they observed that CFG provided more substantial improvements for original units than normalized ones, suggesting that the regularization effect from CFG is more pronounced when the input data has greater variability <Paper corpusId=\"269983348\" paperTitle=\"(Tan et al., 2024)\" isShortName></Paper>.\n\nHuman evaluations have also confirmed CFG's effectiveness. In a user study conducted by Sanchez et al., there was a 75% preference for GPT4All using CFG over the baseline model when handling challenging form-driven and content-driven prompts <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>. Similarly, GLIDE's implementation of CFG yielded more preferable results in both image photo-realism and textual alignment according to human evaluators <Paper corpusId=\"268264822\" paperTitle=\"(Cao et al., 2024)\" isShortName></Paper>.\n\nHowever, not all implementations of CFG have shown significant improvements. Xu reported that their text generation model failed to improve substantially over a non-guided baseline, with only marginal BLEU score improvements on the validation set <Paper corpusId=\"252780170\" paperTitle=\"(Xu, 2022)\" isShortName></Paper>. This suggests that the effectiveness of CFG may depend on the specific model architecture, training procedure, and application domain.\n\nThe guidance strength parameter (w or \u03b3) has emerged as a critical factor affecting performance. Tan et al. found that small values like w = 0.5 or w = 1 empirically brought the most improvement in translation tasks, with these improvements becoming more noticeable as the number of decoding iterations increased <Paper corpusId=\"269983348\" paperTitle=\"(Tan et al., 2024)\" isShortName></Paper>. Jolicoeur-Martineau et al. used w = 1.5 as a general default value in their analyses, though they acknowledged that practitioners could tune this parameter for further performance gains <Paper corpusId=\"271161847\" paperTitle=\"(Jolicoeur-Martineau et al., 2024)\" isShortName></Paper>.\n\nAn important consideration in evaluating CFG is the timing and intensity of guidance during the sampling process. Dinh et al. discovered that applying strong guidance throughout the entire sampling process could be counterproductive due to \"model-fitting issues,\" where samples become overly tuned to match the classifier's parameters rather than generalizing the expected condition <Paper corpusId=\"271915699\" paperTitle=\"(Dinh et al., 2024)\" isShortName></Paper>. Their work demonstrated that reducing or excluding guidance at numerous timesteps could mitigate this issue <Paper corpusId=\"271915699\" paperTitle=\"(Dinh et al., 2024)\" isShortName></Paper>.\n\nDespite these challenges, CFG has been successfully incorporated into various tasks based on diffusion models, with Guo et al. highlighting the contribution of different guidance strengths to improving result quality during sampling <Paper corpusId=\"276107584\" paperTitle=\"(Guo et al., 2025)\" isShortName></Paper>. A limitation consistently noted across studies is that CFG requires careful tuning and exploration, as guidance values that work well in one context (such as long-form generation) might be poorly suited for another <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.", "citations": [{"id": "(Sanchez et al., 2023)", "paper": {"corpus_id": 259308807, "title": "Stay on topic with Classifier-Free Guidance", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Guillaume Sanchez", "authorId": "2056723344"}, {"name": "Honglu Fan", "authorId": "2072838294"}, {"name": "Alexander Spangher", "authorId": "51444076"}, {"name": "Elad Levi", "authorId": "34490455"}, {"name": "Pawan Sasanka Ammanamanchi", "authorId": "1451644426"}, {"name": "Stella Biderman", "authorId": "103476203"}], "n_citations": 55}, "snippets": ["In this work, we demonstrate that CFG can be used broadly as an inference-time technique in pure language modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family models across an array of tasks: Q\\&A, reasoning, code generation, and machine translation, achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent to a model with twice the parameter-count; (3) can stack alongside other inference-time methods like Chain-of-Thought and Self-Consistency, yielding further improvements in difficult tasks; (4) can be used to increase the faithfulness and coherence of assistants in challenging form-driven and content-driven prompts: in a human evaluation we show a 75\\% preference for GPT4All using CFG over baseline.\n\nIn contrast to text-to-vision, CFG in autoregressive language modeling works out-of-the-box, without the need to further train the model.\n\nOur work also integrates into a growing body of inference techniques aimed at perturbing the logit distributions of an LM [45]73]. We demonstrate that by doubling the inference FLOP using CFG brings performances of a model about twice the size. This allows training smaller models, which can be ran on smaller hardware, and are cheaper to train.\n\nOur work faces the following limitations: CFG requires tweaking and exploration: \u03b3 values that might work in one context (i.e. long-form generation) might be poorly suited for another context."], "score": 0.95947265625}, {"id": "(Tan et al., 2024)", "paper": {"corpus_id": 269983348, "title": "DiffNorm: Self-Supervised Normalization for Non-autoregressive Speech-to-speech Translation", "year": 2024, "venue": "Neural Information Processing Systems", "authors": [{"name": "Weiting Tan", "authorId": "28000727"}, {"name": "Jingyu (Jack) Zhang", "authorId": "2167508843"}, {"name": "Lingfeng Shen", "authorId": "2248152247"}, {"name": "Daniel Khashabi", "authorId": "1783281"}, {"name": "Philipp Koehn", "authorId": "2264196844"}], "n_citations": 0}, "snippets": ["In this section, we compare non-autoregressive transformers trained with and without classifier-free guidance (CG). We train CMLM models with classifier-free guidance and evaluate them with 5, 10, 15 iterations of decoding. From Table 8, we observe that CG improves the quality of translation whether the model is trained on original or normalized speech units. We find CG brings more improvement on the original units than the normalized units. This happens because normalized speech units are more conformed and already result in a large improvement in their translation quality, making the regularization effect from CG less obvious. Nevertheless, the best-performing system is achieved with both DIFFNORM and CG. \n\nComparing different hyperparameters w, we find a small value like w = 0.5 or w = 1 brings the most improvement empirically, and such improvements are more noticeable when the number of decoding iterations is larger. For example, comparing the results under 5 and 15 iterations, we find w = 0 gives better results when the number of iterations is small while w = 0.5 obtains the best performance with 15 iterations."], "score": 0.927734375}, {"id": "(Cao et al., 2024)", "paper": {"corpus_id": 268264822, "title": "Controllable Generation with Text-to-Image Diffusion Models: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Pu Cao", "authorId": "2203366502"}, {"name": "Feng Zhou", "authorId": "2273950538"}, {"name": "Qing Song", "authorId": "2273931256"}, {"name": "Lu Yang", "authorId": "39702333"}], "n_citations": 38}, "snippets": ["GLIDE additionally investigates classifier-free guidance (CFG) for comparison, which yields more preferable results in both image photo-realism and textual alignment by human evaluators and is chosen as the fundamental mechanism for text-to-image generation."], "score": 0.88037109375}, {"id": "(Xu, 2022)", "paper": {"corpus_id": 252780170, "title": "CLIP-Diffusion-LM: Apply Diffusion Model on Image Captioning", "year": 2022, "venue": "arXiv.org", "authors": [{"name": "Shi-You Xu", "authorId": "2174547685"}], "n_citations": 12}, "snippets": ["The effectiveness of applying classification-free guidance is examined in our model. The guidance provided is the CLIP text feature of ground truth label caption. Table 1 shows the comparison between the baseline and classification-free guidance-trained model. In contrast to the previous success of applying classification-free guidance, our model fails to improve significantly over none classification guided baseline. We further test the 2 classification-free-guided models' performance by evaluating BLEU score on the validation set. The model trained using classifier-free guidance hardly outperform the simpler baseline model, with the parameter suggested by Jonathan and Tim [32] (w = 0."], "score": 0.8193359375}, {"id": "(Jolicoeur-Martineau et al., 2024)", "paper": {"corpus_id": 271161847, "title": "Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Alexia Jolicoeur-Martineau", "authorId": "2303409806"}, {"name": "A. Baratin", "authorId": "14398916"}, {"name": "Kisoo Kwon", "authorId": "2311115257"}, {"name": "Boris Knyazev", "authorId": "49934559"}, {"name": "Yan Zhang", "authorId": "49889702"}], "n_citations": 1}, "snippets": ["To enforce better conditioning of the properties, we use classifier-free guidance, originally designed for diffusion models (Ho & Salimans, 2022), and found beneficial for autoregressive language models as well (Sanchez et al., 2023). This technique involves directing the model more toward the conditional model's direction while pushing it away from the unconditional model's direction by an equal amount. Figure 2 illustrates this concept. The amount of guidance typically requires hyperparameter-tuning. However, for simplicity and generality, in all analyses, we arbitrarily set the guidance parameter w to 1.5, where w = 1 means no guidance. Practitioners can tune the guidance for further performance gain."], "score": 0.92578125}, {"id": "(Dinh et al., 2024)", "paper": {"corpus_id": 271915699, "title": "Compress Guidance in Conditional Diffusion Sampling", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Anh-Dung Dinh", "authorId": "2153473846"}, {"name": "Daochang Liu", "authorId": "51023221"}, {"name": "Chang Xu", "authorId": "2288626806"}], "n_citations": 0}, "snippets": ["We found that enforcing guidance throughout the sampling process is often counterproductive due to the model-fitting issue, where samples are 'tuned' to match the classifier's parameters rather than generalizing the expected condition. This work identifies and quantifies the problem, demonstrating that reducing or excluding guidance at numerous timesteps can mitigate this issue."], "score": 0.93017578125}, {"id": "(Guo et al., 2025)", "paper": {"corpus_id": 276107584, "title": "MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Ziyan Guo", "authorId": "2112225563"}, {"name": "Zeyu Hu", "authorId": "2343790499"}, {"name": "Na Zhao", "authorId": "2343735032"}, {"name": "De Wen Soh", "authorId": "2258965291"}], "n_citations": 3}, "snippets": ["Classifier-Free Guidance (CFG) [Ho and Salimans 2022] has been incorporated for various tasks (Peng et al., 2024)Zhang et al. 2024Zhang et al. , 2025b] ] based on diffusion models. As shown in Table12, strengths of classifier free guidance for each task are presented, which contributing to the results' quality during sampling."], "score": 0.91162109375}], "table": null}, {"title": "Advantages of Classifier-Free Guidance in NLP", "tldr": "Classifier-free guidance offers significant advantages in NLP applications, including improved performance across diverse tasks without model retraining, computational efficiency equivalent to using models with twice the parameter count, and enhanced controllability of generated outputs. (5 sources)", "text": "\n- **No Need for Separate Classifier Models**: CFG eliminates the requirement to train additional classifier models, simplifying the guidance process while leveraging the generative model's own knowledge for better directional control <Paper corpusId=\"257102889\" paperTitle=\"(Huang et al., 2023)\" isShortName></Paper> <Paper corpusId=\"249145348\" paperTitle=\"(Ho, 2022)\" isShortName></Paper>.\n\n- **Works \"Out-of-the-Box\" for Language Models**: Unlike text-to-image applications, CFG can be implemented in autoregressive language models without additional training, making it immediately applicable to existing pre-trained models <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\n- **Significant Performance Improvements**: CFG has been shown to enhance performance across a wide range of NLP tasks including question answering, reasoning, code generation, and machine translation, achieving state-of-the-art results in some benchmarks <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\n- **Computational Efficiency**: Implementing CFG provides performance improvements equivalent to using a model with twice the parameter count, effectively doubling inference efficiency while maintaining comparable quality. This allows for training smaller models that can run on more modest hardware with lower training costs <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\n- **Compatible with Other Inference Techniques**: CFG can be effectively combined with other inference-time methods such as Chain-of-Thought and Self-Consistency, yielding further improvements particularly on difficult tasks <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\n- **Flexible Conditioning Control**: The guidance weight parameter (w) allows practitioners to control the degree of conditioning influence, offering a tunable mechanism to balance between unconditional generation and strict adherence to conditioning information <Paper corpusId=\"259095911\" paperTitle=\"(Chang et al., 2023)\" isShortName></Paper> <Paper corpusId=\"271161847\" paperTitle=\"(Jolicoeur-Martineau et al., 2024)\" isShortName></Paper>.\n\n- **Enhanced Cross-Modal Guidance**: For multimodal applications, CFG strengthens directional guidance between different modalities (such as text and images), improving alignment between generated content and conditioning information <Paper corpusId=\"257102889\" paperTitle=\"(Huang et al., 2023)\" isShortName></Paper>.\n\n- **Improved Handling of Complex Conditioning**: CFG is particularly effective when dealing with conditioning information that would be difficult to predict using a traditional classifier, making it suitable for complex NLP tasks with nuanced conditioning requirements <Paper corpusId=\"257102889\" paperTitle=\"(Huang et al., 2023)\" isShortName></Paper>.\n\n- **Increased Output Faithfulness and Coherence**: Human evaluations have demonstrated a strong preference for outputs generated using CFG, with a 75% preference rate for assistant responses on challenging form-driven and content-driven prompts <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.", "citations": [{"id": "(Huang et al., 2023)", "paper": {"corpus_id": 257102889, "title": "Region-Aware Diffusion for Zero-shot Text-driven Image Editing", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Nisha Huang", "authorId": "2186281333"}, {"name": "Fan Tang", "authorId": "1443761295"}, {"name": "Weiming Dong", "authorId": "40441149"}, {"name": "Tong-Yee Lee", "authorId": "39945992"}, {"name": "Changsheng Xu", "authorId": "2155590336"}], "n_citations": 26}, "snippets": ["Enhanced Directional Guidance. To reinforce the editing direction of the source region to follow the target text, we attempt to modify a classifier-free guidance (Ho, 2022) to strengthen cross-modal guidance. It is a strategy for guiding diffusion models without necessitating the training of a separate classifier model. Generally, classifier-free guidance offers two benefits. For starters, rather than relying on the knowledge of a separate (and perhaps smaller) categorization model, it allows a single model to leverage its experience while guiding. Second, it simplifies directing when conditioned on information that is difficult to predict using a classifier."], "score": 0.9619140625}, {"id": "(Ho, 2022)", "paper": {"corpus_id": 249145348, "title": "Classifier-Free Diffusion Guidance", "year": 2022, "venue": "arXiv.org", "authors": [{"name": "Jonathan Ho", "authorId": "2126278"}], "n_citations": 3970}, "snippets": ["Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance."], "score": 0.0}, {"id": "(Sanchez et al., 2023)", "paper": {"corpus_id": 259308807, "title": "Stay on topic with Classifier-Free Guidance", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Guillaume Sanchez", "authorId": "2056723344"}, {"name": "Honglu Fan", "authorId": "2072838294"}, {"name": "Alexander Spangher", "authorId": "51444076"}, {"name": "Elad Levi", "authorId": "34490455"}, {"name": "Pawan Sasanka Ammanamanchi", "authorId": "1451644426"}, {"name": "Stella Biderman", "authorId": "103476203"}], "n_citations": 55}, "snippets": ["In this work, we demonstrate that CFG can be used broadly as an inference-time technique in pure language modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family models across an array of tasks: Q\\&A, reasoning, code generation, and machine translation, achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent to a model with twice the parameter-count; (3) can stack alongside other inference-time methods like Chain-of-Thought and Self-Consistency, yielding further improvements in difficult tasks; (4) can be used to increase the faithfulness and coherence of assistants in challenging form-driven and content-driven prompts: in a human evaluation we show a 75\\% preference for GPT4All using CFG over baseline.\n\nIn contrast to text-to-vision, CFG in autoregressive language modeling works out-of-the-box, without the need to further train the model.\n\nOur work also integrates into a growing body of inference techniques aimed at perturbing the logit distributions of an LM [45]73]. We demonstrate that by doubling the inference FLOP using CFG brings performances of a model about twice the size. This allows training smaller models, which can be ran on smaller hardware, and are cheaper to train.\n\nOur work faces the following limitations: CFG requires tweaking and exploration: \u03b3 values that might work in one context (i.e. long-form generation) might be poorly suited for another context."], "score": 0.95947265625}, {"id": "(Chang et al., 2023)", "paper": {"corpus_id": 259095911, "title": "On the Design Fundamentals of Diffusion Models: A Survey", "year": 2023, "venue": "Pattern Recognition", "authors": [{"name": "Ziyi Chang", "authorId": "2186402069"}, {"name": "G. Koulieris", "authorId": "2872629"}, {"name": "Hubert P. H. Shum", "authorId": "1993718816"}], "n_citations": 56}, "snippets": ["To avoid the extra classifier, classifier-free guidance replaces the classifier by a mixture of unconditional model and vanilla guidance. It encourages the model in the direction of guidance and simultaneously discourages away from unconditional direction [196]. As shown in Figure 13, instead of training two models, a conditional model and an unconditional one are formulated uniformly by dropping out conditions c with a probability p [172]. The two models are learned jointly as if they were a singular conditional model [24]. In particular, classifier-free guidance is formulated as: \n\nwhere w is the weight of conditions. The weight is slightly different from its counterpart in classifier guidance. When w = 0, the classifier-free guidance becomes unconditional models without vanilla guidance. The vanilla guidance is a special case when w = 1. In this case, the unconditional model is suppressed and conditions are incorporated through vanilla guidance [38]. If w > 1, the classifier-free guidance restrains the unconditional model and prioritizes conditions further by larger weights. The score from classifier-free guidance deviates quickly away from the unconditional score, and thus, samples that better satisfy the conditions will be generated [197]."], "score": 0.97119140625}, {"id": "(Jolicoeur-Martineau et al., 2024)", "paper": {"corpus_id": 271161847, "title": "Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Alexia Jolicoeur-Martineau", "authorId": "2303409806"}, {"name": "A. Baratin", "authorId": "14398916"}, {"name": "Kisoo Kwon", "authorId": "2311115257"}, {"name": "Boris Knyazev", "authorId": "49934559"}, {"name": "Yan Zhang", "authorId": "49889702"}], "n_citations": 1}, "snippets": ["To enforce better conditioning of the properties, we use classifier-free guidance, originally designed for diffusion models (Ho & Salimans, 2022), and found beneficial for autoregressive language models as well (Sanchez et al., 2023). This technique involves directing the model more toward the conditional model's direction while pushing it away from the unconditional model's direction by an equal amount. Figure 2 illustrates this concept. The amount of guidance typically requires hyperparameter-tuning. However, for simplicity and generality, in all analyses, we arbitrarily set the guidance parameter w to 1.5, where w = 1 means no guidance. Practitioners can tune the guidance for further performance gain."], "score": 0.92578125}], "table": null}, {"title": "Limitations and Challenges", "tldr": "Despite its benefits, classifier-free guidance in NLP faces significant limitations including computational overhead from requiring dual forward passes, challenges in tuning guidance parameters, and issues with model underfitting that can lead to suboptimal results. (8 sources)", "text": "\n- **Computational Overhead**: CFG requires performing both conditional and unconditional inference for each sampling step, effectively doubling the computational requirements during inference, which limits its applicability in real-time scenarios <Paper corpusId=\"278171703\" paperTitle=\"(Liang et al., 2025)\" isShortName></Paper>.\n\n- **Parameter Tuning Challenges**: The guidance strength parameter requires careful tuning and exploration, as values that work well in one context (such as long-form generation) might be poorly suited for another context <Paper corpusId=\"259308807\" paperTitle=\"(Sanchez et al., 2023)\" isShortName></Paper>.\n\n- **Fixed Attributes During Training**: A fundamental limitation of CFG is that the attributes used for guidance must be fixed during the training process, limiting flexibility when new guidance criteria are needed post-training <Paper corpusId=\"272593086\" paperTitle=\"(Kerby et al., 2024)\" isShortName></Paper> <Paper corpusId=\"249145348\" paperTitle=\"(Ho, 2022)\" isShortName></Paper>.\n\n- **Inconsistent Performance Across Applications**: While CFG has shown significant improvements in some NLP tasks, it has failed to deliver substantial benefits in others. Some text generation models showed only marginal BLEU score improvements over non-guided baselines <Paper corpusId=\"252780170\" paperTitle=\"(Xu, 2022)\" isShortName></Paper>.\n\n- **Model-Fitting Issues**: Applying strong guidance throughout the entire sampling process can be counterproductive due to \"model-fitting issues,\" where samples become overly tuned to match the classifier's parameters rather than generalizing the expected condition <Paper corpusId=\"271915699\" paperTitle=\"(Dinh et al., 2024)\" isShortName></Paper>.\n\n- **Sensitivity to Underfitting**: When a model is underfitted, CFG can guide samples in directions that significantly deviate from optimal trajectories. The mismatch between conditional and unconditional predictions during sampling can cause the estimated velocity to contradict the optimal velocity, particularly in the first step of generation <Paper corpusId=\"277510202\" paperTitle=\"(Fan et al., 2025)\" isShortName></Paper>.\n\n- **Training Instability with Higher Guidance Weights**: Implementing higher guidance weights during training (w \u2265 1) can lead to model collapse or prevent normal inference, resulting in noise output instead of meaningful content <Paper corpusId=\"278171703\" paperTitle=\"(Liang et al., 2025)\" isShortName></Paper>.\n\n- **Integration Complexity**: Unifying conditional and unconditional models requires careful implementation of condition dropout during training, necessitating additional model components like learned \"null\" embeddings <Paper corpusId=\"276647345\" paperTitle=\"(Zhu et al., 2025)\" isShortName></Paper>.\n\n- **Balance Between Fidelity and Diversity**: Achieving the optimal balance between output fidelity and diversity through the guidance coefficient requires experimentation and may vary depending on the specific task and domain <Paper corpusId=\"276647345\" paperTitle=\"(Zhu et al., 2025)\" isShortName></Paper>.", "citations": [{"id": "(Liang et al., 2025)", "paper": {"corpus_id": 278171703, "title": "Towards Flow-Matching-based TTS without Classifier-Free Guidance", "year": 2025, "venue": "", "authors": [{"name": "Yuzhe Liang", "authorId": "2278618341"}, {"name": "Wenzhe Liu", "authorId": "2358111037"}, {"name": "Chunyu Qiang", "authorId": "2358041541"}, {"name": "Zhikang Niu", "authorId": "2229877177"}, {"name": "Yushen Chen", "authorId": "2324996330"}, {"name": "Ziyang Ma", "authorId": "2116609277"}, {"name": "Wenxi Chen", "authorId": "2278584538"}, {"name": "Nan Li", "authorId": "2358116915"}, {"name": "Chen Zhang", "authorId": "2358098456"}, {"name": "Xie Chen", "authorId": "2321881822"}], "n_citations": 0}, "snippets": ["However, CFG incurs substantial computational cost as it requires two forward passes, which hinders its applicability in real-time scenarios", "another core factor affecting inference efficiency is the widespread use of classifier-free guidance (CFG), which requires performing both conditional and unconditional inference for each sampling step, effectively doubling the computational overhead during inference. In the field of image generation, Tang et al. [20] proposed a model-guidance training approach that enables diffusion models to remove the need for CFG at inference time", "When w is slightly increased, model training tends to collapse. Based on empirical values from Classifier-Free Guidance (CFG) reasoning, we aimed to set w close to the target value of 2, which is used in the F5-TTS inference process. However, during actual training, we found that setting w \u2265 1 for training, the model training loss will not collapse, but it will lead to the model can't inference normally, and the inference results are all noise, the analysis is that if we don't use stop gradient, the vt(x0) gradient back-propagation will cause the model to learn the value of a trival."], "score": 0.94580078125}, {"id": "(Sanchez et al., 2023)", "paper": {"corpus_id": 259308807, "title": "Stay on topic with Classifier-Free Guidance", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Guillaume Sanchez", "authorId": "2056723344"}, {"name": "Honglu Fan", "authorId": "2072838294"}, {"name": "Alexander Spangher", "authorId": "51444076"}, {"name": "Elad Levi", "authorId": "34490455"}, {"name": "Pawan Sasanka Ammanamanchi", "authorId": "1451644426"}, {"name": "Stella Biderman", "authorId": "103476203"}], "n_citations": 55}, "snippets": ["In this work, we demonstrate that CFG can be used broadly as an inference-time technique in pure language modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family models across an array of tasks: Q\\&A, reasoning, code generation, and machine translation, achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent to a model with twice the parameter-count; (3) can stack alongside other inference-time methods like Chain-of-Thought and Self-Consistency, yielding further improvements in difficult tasks; (4) can be used to increase the faithfulness and coherence of assistants in challenging form-driven and content-driven prompts: in a human evaluation we show a 75\\% preference for GPT4All using CFG over baseline.\n\nIn contrast to text-to-vision, CFG in autoregressive language modeling works out-of-the-box, without the need to further train the model.\n\nOur work also integrates into a growing body of inference techniques aimed at perturbing the logit distributions of an LM [45]73]. We demonstrate that by doubling the inference FLOP using CFG brings performances of a model about twice the size. This allows training smaller models, which can be ran on smaller hardware, and are cheaper to train.\n\nOur work faces the following limitations: CFG requires tweaking and exploration: \u03b3 values that might work in one context (i.e. long-form generation) might be poorly suited for another context."], "score": 0.95947265625}, {"id": "(Kerby et al., 2024)", "paper": {"corpus_id": 272593086, "title": "Training-Free Guidance for Discrete Diffusion Models for Molecular Generation", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Thomas Kerby", "authorId": "2243157079"}, {"name": "Kevin R. Moon", "authorId": "2243003711"}], "n_citations": 3}, "snippets": ["Classifier-free guidance addresses this issue by training a diffusion model that can condition on specific attributes, allowing for both unconditional and conditional generation (Ho, 2022). During sampling, classifier-free guidance combines the outputs of a single model, both when conditioned on specific attributes and when unconditioned, effectively guiding the generation process toward the desired attributes, similar to how a Bayes classifier influences predictions. However, the main drawback of this method is that the attributes for guidance must be fixed beforehand during training."], "score": 0.970703125}, {"id": "(Ho, 2022)", "paper": {"corpus_id": 249145348, "title": "Classifier-Free Diffusion Guidance", "year": 2022, "venue": "arXiv.org", "authors": [{"name": "Jonathan Ho", "authorId": "2126278"}], "n_citations": 3970}, "snippets": ["Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance."], "score": 0.0}, {"id": "(Xu, 2022)", "paper": {"corpus_id": 252780170, "title": "CLIP-Diffusion-LM: Apply Diffusion Model on Image Captioning", "year": 2022, "venue": "arXiv.org", "authors": [{"name": "Shi-You Xu", "authorId": "2174547685"}], "n_citations": 12}, "snippets": ["The effectiveness of applying classification-free guidance is examined in our model. The guidance provided is the CLIP text feature of ground truth label caption. Table 1 shows the comparison between the baseline and classification-free guidance-trained model. In contrast to the previous success of applying classification-free guidance, our model fails to improve significantly over none classification guided baseline. We further test the 2 classification-free-guided models' performance by evaluating BLEU score on the validation set. The model trained using classifier-free guidance hardly outperform the simpler baseline model, with the parameter suggested by Jonathan and Tim [32] (w = 0."], "score": 0.8193359375}, {"id": "(Dinh et al., 2024)", "paper": {"corpus_id": 271915699, "title": "Compress Guidance in Conditional Diffusion Sampling", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Anh-Dung Dinh", "authorId": "2153473846"}, {"name": "Daochang Liu", "authorId": "51023221"}, {"name": "Chang Xu", "authorId": "2288626806"}], "n_citations": 0}, "snippets": ["We found that enforcing guidance throughout the sampling process is often counterproductive due to the model-fitting issue, where samples are 'tuned' to match the classifier's parameters rather than generalizing the expected condition. This work identifies and quantifies the problem, demonstrating that reducing or excluding guidance at numerous timesteps can mitigate this issue."], "score": 0.93017578125}, {"id": "(Fan et al., 2025)", "paper": {"corpus_id": 277510202, "title": "CFG-Zero*: Improved Classifier-Free Guidance for Flow Matching Models", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Weichen Fan", "authorId": "2340406432"}, {"name": "Amber Yijia Zheng", "authorId": "2323508574"}, {"name": "Raymond A. Yeh", "authorId": "2240073241"}, {"name": "Ziwei Liu", "authorId": "2324070583"}], "n_citations": 2}, "snippets": ["Next, classifier-free guidance (CFG) [9]44] is a widely used technique in flow matching models to improve sample quality and controllability during generation. In textto-image tasks, CFG improves the alignment between generated images and input text prompts. In other words, CFG is used because the conditional distribution induced by the learned conditional velocity does not fully match with the user's \"intended\" conditional distribution; see example in Fig. 2. We hypothesize that this mismatch arises from two fundamental factors. First, it may be from dataset limitations, where the user's interpretation of a text prompt and its corresponding image differs from the dataset distribution. Second, it could result from a learning limitation, where the learned velocity fails to accurately capture the dataset's distribution. In this work, we focus on the latter issue. When the model is underfitted, a mismatch exists between the conditional and unconditional predictions during sampling, causing CFG to guide the sample in a direction that deviates significantly from the optimal trajectory. Specifically, the velocity estimated by CFG in the first step at x 0 may contradict the optimal velocity. This suggests that skipping this prediction could lead to better results."], "score": 0.97607421875}, {"id": "(Zhu et al., 2025)", "paper": {"corpus_id": 276647345, "title": "Language-Informed Hyperspectral Image Synthesis for Imbalanced-Small Sample Classification via Semi-Supervised Conditional Diffusion Model", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Yimin Zhu", "authorId": "2347677379"}, {"name": "Linlin Xu", "authorId": "2347797817"}], "n_citations": 1}, "snippets": ["Following classifier-free guidance diffusion [83], we set \u03b5\u03b8 = (1 + \u03c9)\u03f5 \u03b8 (z t , t, c) \u2212 \u03c9\u03f5 \u03b8 (z t , t, c = \u2298). c = \u2298 is done by randomly dropping out c during training and replacing it with a learned \"null\" embedding \u2298. Generally, training with classifier-free guidance requires two models: an unconditional generation model and a conditional generation model. However, these two models can be unified into a single model by probabilistically omitting the language condition during training. During inference, the final result can be achieved by linear extrapolation between the conditional and unconditional generations. This allows for adjustment of the generation effect to balance the fidelity and diversity of the generated samples by changing the guidance coefficient \u03c9."], "score": 0.92041015625}], "table": null}], "cost": 0.476886}}
