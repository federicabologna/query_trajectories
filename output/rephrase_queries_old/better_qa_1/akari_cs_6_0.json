{"better_query": "What are the latest techniques for fine-tuning both the retriever and generator components in Retrieval Augmented Generation (RAG) systems, and how do dual fine-tuning approaches like RA-DIT and RankRAG compare in performance to single-component tuning?", "better_answer": {"sections": [{"title": "Introduction to RAG Systems", "tldr": "Retrieval-Augmented Generation (RAG) combines large language models with external knowledge sources through retrieval mechanisms to enhance text generation. This framework consists of two core components: a retriever that fetches relevant information and a generator that synthesizes coherent responses using the retrieved content. (4 sources)", "text": "\nRetrieval-Augmented Generation (RAG) represents a significant advancement in natural language processing by combining the capabilities of large language models (LLMs) with external knowledge sources through a retrieval mechanism. Unlike traditional language models that generate text based solely on their internal parametric knowledge, RAG models retrieve relevant information from knowledge bases and integrate this external data into the generation process <Paper corpusId=\"269149146\" paperTitle=\"(Susnjak et al., 2024)\" isShortName></Paper>. This approach was formally introduced by Lewis et al. in 2020, who demonstrated that RAG models could overcome the limitations of purely parametric models by providing them with explicit access to non-parametric memory <Paper corpusId=\"270870796\" paperTitle=\"(Mai et al., 2024)\" isShortName></Paper> <Paper corpusId=\"218869575\" paperTitle=\"(Lewis et al., 2020)\" isShortName></Paper>.\n\nThe architecture of RAG systems consists of two primary components. First, the retrieval mechanism is responsible for fetching relevant documents or data from external sources. Second, the generative model synthesizes this retrieved information into coherent and contextually appropriate responses <Paper corpusId=\"269149146\" paperTitle=\"(Susnjak et al., 2024)\" isShortName></Paper>. The integration of these components allows RAG systems to generate more specific, diverse, and factual language than state-of-the-art parametric-only models <Paper corpusId=\"218869575\" paperTitle=\"(Lewis et al., 2020)\" isShortName></Paper>.\n\nModern implementations of RAG have been facilitated by frameworks like LangChain, which provides various tools allowing large models to access real-time information from diverse sources such as Google Search, vector databases, or knowledge graphs <Paper corpusId=\"270870796\" paperTitle=\"(Mai et al., 2024)\" isShortName></Paper> <Paper corpusId=\"260223847\" paperTitle=\"(Topsakal et al., 2023)\" isShortName></Paper>. This library has gained significant recognition in the AI community for its ability to streamline the development of LLM-based applications that can seamlessly interact with various data sources <Paper corpusId=\"260223847\" paperTitle=\"(Topsakal et al., 2023)\" isShortName></Paper>.", "citations": [{"id": "(Susnjak et al., 2024)", "paper": {"corpus_id": 269149146, "title": "Automating Research Synthesis with Domain-Specific Large Language Model Fine-Tuning", "year": 2024, "venue": "ACM Transactions on Knowledge Discovery from Data", "authors": [{"name": "Teo Su\u0161njak", "authorId": "2656889"}, {"name": "Peter Hwang", "authorId": "2296719088"}, {"name": "N. Reyes", "authorId": "1783269"}, {"name": "A. Barczak", "authorId": "3312622"}, {"name": "Timothy R. McIntosh", "authorId": "11430146"}, {"name": "Surangika Ranathunga", "authorId": "143976433"}], "n_citations": 26}, "snippets": ["Retrieval-Augmented Generation (RAG) [68] is a framework that combines the capabilities of large language models (LLMs) with external knowledge sources through a retrieval mechanism.Unlike traditional language models that generate text based solely on the text's internal representation, RAG models retrieve relevant information from a knowledge base (like a database or the internet) and integrate this into the generation process.The core components of RAG include the retrieval mechanism, which fetches relevant documents or data, and the generative model, which synthesizes the retrieved information into coherent and contextually relevant responses."], "score": 0.90576171875}, {"id": "(Mai et al., 2024)", "paper": {"corpus_id": 270870796, "title": "From Efficient Multimodal Models to World Models: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Xinji Mai", "authorId": "2276937443"}, {"name": "Zeng Tao", "authorId": "2261831274"}, {"name": "Junxiong Lin", "authorId": "2261891655"}, {"name": "Haoran Wang", "authorId": "2276807843"}, {"name": "Yang Chang", "authorId": "2276969811"}, {"name": "Yanlan Kang", "authorId": "2212014366"}, {"name": "Yan Wang", "authorId": "2276879376"}, {"name": "Wenqiang Zhang", "authorId": "2276819302"}], "n_citations": 5}, "snippets": ["Retrieval-Augmented Generation (RAG) (Lewis et al., 2020) combines information retrieval and generative models, enhancing generative model performance by retrieving relevant information from external data sources.The LangChain (Topsakal et al., 2023) library provides various tools allowing large models to access real-time information from sources like Google Search, vector databases, or knowledge graphs, further improving RAG effectiveness."], "score": 0.9267578125}, {"id": "(Lewis et al., 2020)", "paper": {"corpus_id": 218869575, "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "year": 2020, "venue": "Neural Information Processing Systems", "authors": [{"name": "Patrick Lewis", "authorId": "145222654"}, {"name": "Ethan Perez", "authorId": "3439053"}, {"name": "Aleksandara Piktus", "authorId": "1716179427"}, {"name": "F. Petroni", "authorId": "40052301"}, {"name": "Vladimir Karpukhin", "authorId": "2067091563"}, {"name": "Naman Goyal", "authorId": "39589154"}, {"name": "Heinrich Kuttler", "authorId": "103131985"}, {"name": "M. Lewis", "authorId": "35084211"}, {"name": "Wen-tau Yih", "authorId": "144105277"}, {"name": "Tim Rockt\u00e4schel", "authorId": "2620211"}, {"name": "Sebastian Riedel", "authorId": "48662861"}, {"name": "Douwe Kiela", "authorId": "1743722"}], "n_citations": 6476}, "snippets": ["Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline."], "score": 0.0}, {"id": "(Topsakal et al., 2023)", "paper": {"corpus_id": 260223847, "title": "Creating Large Language Model Applications Utilizing LangChain: A Primer on Developing LLM Apps Fast", "year": 2023, "venue": "International Conference on Applied Engineering and Natural Sciences", "authors": [{"name": "Oguzhan Topsakal", "authorId": "2113663584"}, {"name": "T. Akinci", "authorId": "114751633"}], "n_citations": 211}, "snippets": ["This study focuses on the utilization of Large Language Models (LLMs) for the rapid development of applications, with a spotlight on LangChain, an open-source software library. LLMs have been rapidly adopted due to their capabilities in a range of tasks, including essay composition, code writing, explanation, and debugging, with OpenAI\u2019s ChatGPT popularizing their usage among millions ofusers. The crux of the study centers around LangChain, designed to expedite the development of bespoke AI applications using LLMs. LangChain has been widely recognized in the AI community for its ability to seamlessly interact with various data sources and applications. The paper provides an examination of LangChain's core features, including its components and chains, acting as modular abstractions and customizable, use-case-specific pipelines, respectively. Through a series of practical examples, the study elucidates the potential of this framework in fostering the swift development of LLM-based applications."], "score": 0.0}], "table": null}, {"title": "Retriever-Only Fine-Tuning Techniques", "tldr": "Retriever fine-tuning techniques focus on enhancing the embedding models that represent and retrieve relevant content for RAG systems. These approaches include contrastive learning, domain-specific adaptation, and specialized methods like rule-guided fine-tuning to improve retrieval quality and reduce noise. (7 sources)", "text": "\n- **Contrastive Learning**: This approach forms the foundation of supervised fine-tuning for retrieval models, especially in domain-specific applications. The technique works by reducing the distance between positive (relevant) samples while increasing the distance between negative (irrelevant) samples in the embedding space. <Paper corpusId=\"271571401\" paperTitle=\"(Gao et al., 2024)\" isShortName></Paper> This method has shown significant improvements in representation quality, with implementations like SimCLR demonstrating up to 7% relative improvement over previous state-of-the-art approaches. <Paper corpusId=\"273695367\" paperTitle=\"(Chen et al., 2024)\" isShortName></Paper> <Paper corpusId=\"211096730\" paperTitle=\"(Chen et al., 2020)\" isShortName></Paper>\n\n- **Domain-Specific Adaptation**: Fine-tuning embedding models with domain-specific data has proven particularly valuable in specialized fields like healthcare and law that contain proprietary terminology. While this approach requires additional effort, it substantially enhances retrieval efficiency and domain alignment. <Paper corpusId=\"271571401\" paperTitle=\"(Gao et al., 2024)\" isShortName></Paper>\n\n- **REPLUG Approach**: This method treats the language model as a black box and updates only the retriever model based on final results, allowing for targeted improvements without modifying the generator component. <Paper corpusId=\"268091298\" paperTitle=\"(Zhao et al., 2024)\" isShortName></Paper>\n\n- **Noise Reduction Techniques**: Since noisy retrieval can significantly harm downstream performance (with studies showing up to 27% drop in accuracy when distractors are added), specialized fine-tuning approaches focus on helping retrievers find relevant documents while avoiding damaging ones. <Paper corpusId=\"273185619\" paperTitle=\"(Sriram et al., 2024)\" isShortName></Paper> <Paper corpusId=\"250340232\" paperTitle=\"(Sauchuk et al., 2022)\" isShortName></Paper>\n\n- **Rule-Guided Retriever Fine-Tuning (RGFT-retriever)**: This technique updates language model encoders using contrastive learning objectives where inputs combine queries with explicit rules. The approach trains retrievers to align with specified preferences, recalling more relevant results than retrievers using simple retrieval principles. <Paper corpusId=\"273695367\" paperTitle=\"(Chen et al., 2024)\" isShortName></Paper>\n\n- **Failure-Aware Approaches**: Recognition of retrieval as a critical failure point in RAG systems has led to specialized fine-tuning that addresses the inherent limitations of information retrieval systems. These approaches acknowledge that validation of retrieval quality is only feasible during operation and that robustness evolves rather than being designed in from the start. <Paper corpusId=\"273185619\" paperTitle=\"(Sriram et al., 2024)\" isShortName></Paper> <Paper corpusId=\"266933076\" paperTitle=\"(Barnett et al., 2024)\" isShortName></Paper>", "citations": [{"id": "(Gao et al., 2024)", "paper": {"corpus_id": 271571401, "title": "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Yunfan Gao", "authorId": "2280046531"}, {"name": "Yun Xiong", "authorId": "2275320371"}, {"name": "Meng Wang", "authorId": "2291409458"}, {"name": "Haofen Wang", "authorId": "2256769434"}], "n_citations": 20}, "snippets": ["Retriever Fine-tuning: In cases where the context may diverge from pre-trained corpus, particularly in highly specialized fields like healthcare, law, and other domains abundant in proprietary terminology. While this adjustment demands additional effort, it can substantially enhance retrieval efficiency and domain alignment.\n\nSupervised Fine-Tuning (SFT). Fine-tuning a retrieval model based on labeled domain data is typically done using contrastive learning. This involves reducing the distance between positive samples while increasing the distance between negative samples", ".3) Dual FT: In the RAG system, fine-tuning both the retriever and the generator simultaneously is a unique feature of the RAG system. It is important to note that the emphasis of system fine-tuning is on the coordination between the retriever and the generator. An exemplary implementation is RA-DIT [27], which fine-tunes both the LLM and the retriever. The LM-ft component updates the LLM to maximize the likelihood of the correct answer given the retrieval-augmented instructions while the R-ft component updates the retriever to minimize the KL-Divergence between the retriever score distribution and the LLM preference."], "score": 0.96435546875}, {"id": "(Chen et al., 2024)", "paper": {"corpus_id": 273695367, "title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Zhongwu Chen", "authorId": "2165306772"}, {"name": "Chengjin Xu", "authorId": "2250617116"}, {"name": "Dingmin Wang", "authorId": "2329140108"}, {"name": "Zhen Huang", "authorId": "2273614102"}, {"name": "Yong Dou", "authorId": "67069932"}, {"name": "Jian Guo", "authorId": "2284217200"}], "n_citations": 3}, "snippets": ["For rule-guided retriever fine-tuning (RGFT-retriever), we update the LM encoders in a contrastive learning objective (Chen et al., 2020) and train over supervised fine-tuning data F R provided in our constructed benchmarks, where inputs are the queries plus rules and supervised labels are heuristic oracle documents. Compared with retrievers employed with simple retrieval principles, our fine-tuned retrievers can recall more relevant results, aligned with the preferences of the rules. For rule-guided generator fine-tuning (RGFT-generator), we adopt the supervised instruction-tuning objective (Iyer et al., 2023;Chung et al., 2024) while combining each query q with two components: retrieved documents D q from the retrieval phase and the same set of rules R q consistent with the retrieval phase. The rules introduced in the RGFT-generator train LLMs on how to optimally attribute from the retrieved context into answers by following rules, making RuleRAG leverage the fine-tuned retrievers more rationally. Experiments show our proposed RGFT can further guarantee and boost the retrieval quality and answering accuracy of RuleRAG-FT than RuleRAG-ICL."], "score": 0.92236328125}, {"id": "(Chen et al., 2020)", "paper": {"corpus_id": 211096730, "title": "A Simple Framework for Contrastive Learning of Visual Representations", "year": 2020, "venue": "International Conference on Machine Learning", "authors": [{"name": "Ting Chen", "authorId": "145358498"}, {"name": "Simon Kornblith", "authorId": "40464924"}, {"name": "Mohammad Norouzi", "authorId": "144739074"}, {"name": "Geoffrey E. Hinton", "authorId": "1695689"}], "n_citations": 18878}, "snippets": ["This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels."], "score": 0.0}, {"id": "(Zhao et al., 2024)", "paper": {"corpus_id": 268091298, "title": "Retrieval-Augmented Generation for AI-Generated Content: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Penghao Zhao", "authorId": "2268718776"}, {"name": "Hailin Zhang", "authorId": "2288557803"}, {"name": "Qinhan Yu", "authorId": "2289597580"}, {"name": "Zhengren Wang", "authorId": "2288675277"}, {"name": "Yunteng Geng", "authorId": "2288532368"}, {"name": "Fangcheng Fu", "authorId": "46182701"}, {"name": "Ling Yang", "authorId": "2249513224"}, {"name": "Wentao Zhang", "authorId": "2277807793"}, {"name": "Bin Cui", "authorId": "2277742543"}], "n_citations": 282}, "snippets": ["Retriever Finetuning: The retriever, central to the RAG system, relies on a proficient embedding model [139]- [142] to represent related content and feed the generator, enhancing system performance. \n\nAdditionally, embedding models with strong expressive power can be fine-tuned with domain-specific or task-related data to boost performance in targeted areas. REPLUG [86] treats LM as a black box and update the retriever model based on the final results."], "score": 0.9091796875}, {"id": "(Sriram et al., 2024)", "paper": {"corpus_id": 273185619, "title": "Contrastive Learning to Improve Retrieval for Real-World Fact Checking", "year": 2024, "venue": "FEVER", "authors": [{"name": "Aniruddh Sriram", "authorId": "2165382262"}, {"name": "Fangyuan Xu", "authorId": "2159829626"}, {"name": "Eunsol Choi", "authorId": "2257003422"}, {"name": "Greg Durrett", "authorId": "1814094"}], "n_citations": 1}, "snippets": ["Retrieval-augmented generation (RAG) relies on two key modules: a retriever and a reader/generation model. For many RAG systems, noisy retrieval hurts downstream performance by providing irrelevant or misleading documents (Yoran et al., 2024). (Sauchuk et al., 2022) found that adding distractors can cause a 27% drop on veracity classification accuracy on FEVER. Therefore, it's important for retrievers to find relevant documents and simultaneously avoid damaging ones. Shi et al. (2023) attempts to solve this problem by finetuning the retrieval component while fixing the reader LM, similar to our work. Other approaches like Ke et al. (2024) create a more complex system with a \"bridging\" model between the retriever and reader. Nevertheless, noisy retrieval remains a failure point in RAG systems (Barnett et al., 2024), and tangible downstream gains can be realized by further finetuning."], "score": 0.91357421875}, {"id": "(Sauchuk et al., 2022)", "paper": {"corpus_id": 250340232, "title": "On the Role of Relevance in Natural Language Processing Tasks", "year": 2022, "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "authors": [{"name": "Artsiom Sauchuk", "authorId": "2175275805"}, {"name": "James Thorne", "authorId": "2053211210"}, {"name": "A. Halevy", "authorId": "1770962"}, {"name": "N. Tonellotto", "authorId": "2783910"}, {"name": "F. Silvestri", "authorId": "144925193"}], "n_citations": 16}, "snippets": ["Many recent Natural Language Processing (NLP) task formulations, such as question answering and fact verification, are implemented as a two-stage cascading architecture. In the first stage an IR system retrieves \"relevant'' documents containing the knowledge, and in the second stage an NLP system performs reasoning to solve the task. Optimizing the IR system for retrieving relevant documents ensures that the NLP system has sufficient information to operate over. These recent NLP task formulations raise interesting and exciting challenges for IR, where the end-user of an IR system is not a human with an information need, but another system exploiting the documents retrieved by the IR system to perform reasoning and address the user information need. Among these challenges, as we will show, is that noise from the IR system, such as retrieving spurious or irrelevant documents, can negatively impact the accuracy of the downstream reasoning module. Hence, there is the need to balance maximizing relevance while minimizing noise in the IR system. This paper presents experimental results on two NLP tasks implemented as a two-stage cascading architecture. We show how spurious or irrelevant retrieved results from the first stage can induce errors in the second stage. We use these results to ground our discussion of the research challenges that the IR community should address in the context of these knowledge-intensive NLP tasks."], "score": 0.0}, {"id": "(Barnett et al., 2024)", "paper": {"corpus_id": 266933076, "title": "Seven Failure Points When Engineering a Retrieval Augmented Generation System", "year": 2024, "venue": "2024 IEEE/ACM 3rd International Conference on AI Engineering \u2013 Software Engineering for AI (CAIN)", "authors": [{"name": "Scott Barnett", "authorId": "2052845461"}, {"name": "Stefanus Kurniawan", "authorId": "2266469333"}, {"name": "Srikanth Thudumu", "authorId": "2257020336"}, {"name": "Zach Brannelly", "authorId": "2279020735"}, {"name": "Mohamed Abdelrazek", "authorId": "47505933"}], "n_citations": 92}, "snippets": ["Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.CCS CONCEPTS\u2022 Software and its engineering \u2192 Empirical software validation."], "score": 0.0}], "table": null}, {"title": "Generator-Only Fine-Tuning Techniques", "tldr": "Generator fine-tuning techniques focus on optimizing language models to better process and incorporate retrieved information into their outputs. These approaches include search-augmented instruction learning, domain-specific adaptation, and retrieval-augmented fine-tuning that improves how generators handle both relevant and irrelevant retrieved content. (4 sources)", "text": "\n- **Search-Augmented Instruction Learning (SAIL)**: This approach fine-tunes language models to effectively process and utilize complex search results from various sources. By training on triplets of instruction, grounding information, and response, models learn to filter out distracting passages, select trustworthy information, and perform multi-hop reasoning. SAIL has demonstrated significant improvements in transparency-sensitive tasks like open-ended question answering and fact checking. <Paper corpusId=\"270870251\" paperTitle=\"(Wang et al., 2024)\" isShortName></Paper> <Paper corpusId=\"258865283\" paperTitle=\"(Luo et al., 2023)\" isShortName></Paper>\n\n- **Retrieval-Augmented Fine-Tuning (RAFT)**: This method enhances generator performance by training LLMs on domain data using a mixture of oracle (highly relevant) and distractor document contexts. This approach helps models learn to distinguish between useful and irrelevant information while incorporating domain knowledge, significantly improving in-domain RAG performance. <Paper corpusId=\"276287820\" paperTitle=\"(Bhushan et al., 2025)\" isShortName></Paper>\n\n- **Context Utilization Training**: Some generator fine-tuning techniques specifically focus on improving how LLMs utilize retriever context, ensuring that the generated content remains faithful to the retrieved information and robust against misleading or contradictory passages. These approaches help models develop better reasoning capabilities when presented with multiple information sources. <Paper corpusId=\"270870251\" paperTitle=\"(Wang et al., 2024)\" isShortName></Paper>\n\n- **Domain-Specific RAG Adaptation**: Fine-tuning strategies for RAG can involve further training of pretrained LLMs on specific datasets to enhance performance in domain-specific RAG tasks. These methodologies improve how generators process and utilize retrieved information in specialized contexts where general knowledge might be insufficient. <Paper corpusId=\"272911196\" paperTitle=\"(Chung et al., 2024)\" isShortName></Paper>\n\n- **Long Context Handling**: Some fine-tuning approaches specifically target improving how instruction-tuned LLMs handle longer retrieval contexts, enabling them to better process and synthesize information from extensive retrieved passages without losing coherence or relevance. <Paper corpusId=\"272911196\" paperTitle=\"(Chung et al., 2024)\" isShortName></Paper>", "citations": [{"id": "(Wang et al., 2024)", "paper": {"corpus_id": 270870251, "title": "Searching for Best Practices in Retrieval-Augmented Generation", "year": 2024, "venue": "Conference on Empirical Methods in Natural Language Processing", "authors": [{"name": "Xiaohua Wang", "authorId": "2273537815"}, {"name": "Zhenghua Wang", "authorId": "2308276345"}, {"name": "Xuan Gao", "authorId": "2292070745"}, {"name": "Feiran Zhang", "authorId": "2308226671"}, {"name": "Yixin Wu", "authorId": "2308043953"}, {"name": "Zhibo Xu", "authorId": "2308044030"}, {"name": "Tianyuan Shi", "authorId": "2308036711"}, {"name": "Zhengyuan Wang", "authorId": "2309182278"}, {"name": "Shizheng Li", "authorId": "2309656885"}, {"name": "Qi Qian", "authorId": "2309176521"}, {"name": "Ruicheng Yin", "authorId": "2292032843"}, {"name": "Changze Lv", "authorId": "2220896023"}, {"name": "Xiaoqing Zheng", "authorId": "2257315404"}, {"name": "Xuanjing Huang", "authorId": "2257129987"}], "n_citations": 61}, "snippets": ["Fine-tuning within the RAG framework is crucial for optimizing both retrievers and generators.Some research focuses on fine-tuning the generator to better utilize retriever context (Luo et al., 2023)[31][32], ensuring faithful and robust generated content.Others fine-tune the retriever to learn to retrieve beneficial passages for the generator [33][34][35].Holistic approaches treat RAG as an integrated system, fine-tuning both retriever and generator together to enhance overall performance [36][37][38], despite increased complexity and integration challenges."], "score": 0.9775390625}, {"id": "(Luo et al., 2023)", "paper": {"corpus_id": 258865283, "title": "SAIL: Search-Augmented Instruction Learning", "year": 2023, "venue": "Conference on Empirical Methods in Natural Language Processing", "authors": [{"name": "Hongyin Luo", "authorId": "1944274"}, {"name": "Yung-Sung Chuang", "authorId": "2475831"}, {"name": "Yuan Gong", "authorId": "145802952"}, {"name": "Tianhua Zhang", "authorId": "2146333115"}, {"name": "Yoon Kim", "authorId": "143827730"}, {"name": "Xixin Wu", "authorId": "1847260"}, {"name": "D. Fox", "authorId": "31997718"}, {"name": "H. Meng", "authorId": "145199941"}, {"name": "James R. Glass", "authorId": "145898106"}], "n_citations": 27}, "snippets": ["Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing \\textit{(instruction, grounding information, response)} triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy information selection and multi-hop reasoning, since the retrieved passages might be informative but not contain the instruction-following answer. Experiments show that the fine-tuned SAIL-7B model has a strong instruction-following ability, and it performs significantly better on transparency-sensitive tasks, including open-ended question answering and fact checking."], "score": 0.0}, {"id": "(Bhushan et al., 2025)", "paper": {"corpus_id": 276287820, "title": "Systematic Knowledge Injection into Large Language Models via Diverse Augmentation for Domain-Specific RAG", "year": 2025, "venue": "North American Chapter of the Association for Computational Linguistics", "authors": [{"name": "Kushagra Bhushan", "authorId": "2256382094"}, {"name": "Yatin Nandwani", "authorId": "1392630568"}, {"name": "Dinesh Khandelwal", "authorId": "2345003462"}, {"name": "Sonam Gupta", "authorId": "2320314900"}, {"name": "Gaurav Pandey", "authorId": "2345005348"}, {"name": "Dinesh Raghu", "authorId": "1916865"}, {"name": "Sachindra Joshi", "authorId": "2243011716"}], "n_citations": 2}, "snippets": ["Recently, Zhang et al. introduced Retrieval-Augmented Fine-Tuning (RAFT), a fine-tuning method for LLMs to incorporate domain knowledge and enhance in-domain RAG performance. RAFT combines RAG and fine-tuning by training LLMs on domain data using a mixture of oracle and distractor document contexts."], "score": 0.94189453125}, {"id": "(Chung et al., 2024)", "paper": {"corpus_id": 272911196, "title": "Efficient In-Domain Question Answering for Resource-Constrained Environments", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Isaac Chung", "authorId": "2322992640"}, {"name": "Phat Vo", "authorId": "2322982756"}, {"name": "Arman Kizilkale", "authorId": "2322991957"}, {"name": "Aaron Reite", "authorId": "2322982549"}], "n_citations": 0}, "snippets": ["Recent advances in RAG have expanded its applications across various domains, showcasing its versatility and potential (Yan et al., 2024)", "Fine tuning strategies for RAG involve further training of a pretrained LLM on a specific dataset to enhance its performance in RAG tasks over that dataset. Several studies, such as those by (Lin et al., 2024) and (Xu et al., 2024) have explored different fine tuning methodologies for improving LLMs in RAG tasks. These works focus on the benefits of retrieval on long context (instruction-tuned) LLMs and extending the scope of fine tuning to the retriever."], "score": 0.9091796875}], "table": null}, {"title": "Dual Fine-Tuning Approaches", "tldr": "Dual fine-tuning approaches simultaneously optimize both retriever and generator components of RAG systems, creating better alignment between the two models. Leading methods like RA-DIT and RankRAG have demonstrated significant performance improvements through coordinated training strategies that help each component better serve the other's needs. (19 sources)", "text": "\nDual fine-tuning approaches represent a significant advancement in RAG optimization by recognizing that the retriever and generator components should be optimized together rather than in isolation. This holistic approach aims to create better alignment between the two models, enabling them to function as a cohesive system rather than independent parts <Paper corpusId=\"270870251\" paperTitle=\"(Wang et al., 2024)\" isShortName></Paper>.\n\n## Prominent Dual Fine-Tuning Methods\n\nRetrieval-Augmented Dual Instruction Tuning (RA-DIT) is one of the most influential dual fine-tuning approaches. It operates through two distinct fine-tuning steps: the first updates the language model to better utilize retrieved knowledge while filtering out irrelevant information, and the second fine-tunes the retriever based on feedback from the language model to retrieve more relevant content <Paper corpusId=\"263605962\" paperTitle=\"(Lin et al., 2023)\" isShortName></Paper> <Paper corpusId=\"278635834\" paperTitle=\"(Wang et al., 2025)\" isShortName></Paper>. This lightweight methodology has achieved state-of-the-art performance on knowledge-intensive benchmarks, significantly outperforming previous approaches by up to 8.9% in zero-shot settings <Paper corpusId=\"273969615\" paperTitle=\"(Zhang et al., 2024)\" isShortName></Paper> <Paper corpusId=\"263605962\" paperTitle=\"(Lin et al., 2023)\" isShortName></Paper>.\n\nRankRAG offers another innovative approach by instruction-tuning a single language model for the dual purpose of both context ranking and answer generation. Remarkably, this method achieves superior performance by incorporating just a small fraction of ranking data into the training process, outperforming models exclusively fine-tuned on large volumes of ranking data <Paper corpusId=\"270878612\" paperTitle=\"(Yu et al., 2024)\" isShortName></Paper>.\n\n## Alignment Mechanisms\n\nA key feature of dual fine-tuning is the alignment of scoring functions between retriever and generator. RA-DIT, for example, uses KL divergence to align the retriever's score distribution with the language model's preferences <Paper corpusId=\"266359151\" paperTitle=\"(Gao et al., 2023)\" isShortName></Paper> <Paper corpusId=\"271571401\" paperTitle=\"(Gao et al., 2024)\" isShortName></Paper>. This alignment ensures that the retriever learns to identify and prioritize documents that the generator finds most useful.\n\nOther approaches employ alternating training paradigms where one component is fixed while the other is optimized, and then the roles are reversed <Paper corpusId=\"271903170\" paperTitle=\"(Peng et al., 2024)\" isShortName></Paper>. For instance, AG-RAG enables both components to learn from each other through a joint training strategy where the retriever learns from generator feedback <Paper corpusId=\"276408682\" paperTitle=\"(Zhang et al., 2025)\" isShortName></Paper>.\n\n## Implementation Techniques\n\nSeveral technical innovations have made dual fine-tuning more practical:\n\n1. **Efficient Parameter Optimization**: Techniques like LoRA (Low-Rank Adaptation) <Paper corpusId=\"235458009\" paperTitle=\"(Hu et al., 2021)\" isShortName></Paper> and QLoRA <Paper corpusId=\"258841328\" paperTitle=\"(Dettmers et al., 2023)\" isShortName></Paper> significantly reduce the number of trainable parameters, making dual fine-tuning more computationally feasible <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper>.\n\n2. **Rule-Guided Fine-Tuning**: Some approaches incorporate explicit rules during training, guiding both retrievers and generators to better align with specified preferences. For example, RGFT-retriever updates language model encoders using contrastive learning with queries plus rules, while RGFT-generator teaches language models to optimally attribute information from retrieved context following the same rules <Paper corpusId=\"273695367\" paperTitle=\"(Chen et al., 2024)\" isShortName></Paper> <Paper corpusId=\"211096730\" paperTitle=\"(Chen et al., 2020)\" isShortName></Paper>.\n\n3. **Generator-Guided Retriever Training**: Methods like DKRR and AAR leverage the generator's attention scores or smaller language models to guide retriever training, ensuring retrieved documents align with the generator's needs <Paper corpusId=\"277043297\" paperTitle=\"(Cheng et al., 2025)\" isShortName></Paper>.\n\n## Challenges and Limitations\n\nDespite their effectiveness, dual fine-tuning approaches face several challenges. One significant issue is the computational complexity of jointly optimizing both components <Paper corpusId=\"270870251\" paperTitle=\"(Wang et al., 2024)\" isShortName></Paper>. Some methods attempt to simplify this through independent top-k approximation, where top-k documents are fed into language models one-by-one to re-score their relevance <Paper corpusId=\"278339057\" paperTitle=\"(Shi et al., 2025)\" isShortName></Paper> <Paper corpusId=\"218869575\" paperTitle=\"(Lewis et al., 2020)\" isShortName></Paper>.\n\nHowever, this approximation has been criticized as impractical since RAG systems typically consume multiple documents simultaneously, and exhaustively evaluating all possible document combinations is computationally infeasible <Paper corpusId=\"278339057\" paperTitle=\"(Shi et al., 2025)\" isShortName></Paper> <Paper corpusId=\"269605438\" paperTitle=\"(Zamani et al., 2024)\" isShortName></Paper>. More recent approaches like Stochastic RAG address this by casting retrieval as a stochastic sampling process, enabling more effective end-to-end optimization <Paper corpusId=\"269605438\" paperTitle=\"(Zamani et al., 2024)\" isShortName></Paper>.\n\nAnother challenge is ensuring that dual fine-tuning produces models that remain robust against retrieval noise, as inappropriate retrieved passages can hinder the language model's ability to generate high-quality responses <Paper corpusId=\"270199429\" paperTitle=\"(Fang et al., 2024)\" isShortName></Paper>. Some approaches explicitly address this through adversarial training that helps models recognize and handle noisy contexts.", "citations": [{"id": "(Wang et al., 2024)", "paper": {"corpus_id": 270870251, "title": "Searching for Best Practices in Retrieval-Augmented Generation", "year": 2024, "venue": "Conference on Empirical Methods in Natural Language Processing", "authors": [{"name": "Xiaohua Wang", "authorId": "2273537815"}, {"name": "Zhenghua Wang", "authorId": "2308276345"}, {"name": "Xuan Gao", "authorId": "2292070745"}, {"name": "Feiran Zhang", "authorId": "2308226671"}, {"name": "Yixin Wu", "authorId": "2308043953"}, {"name": "Zhibo Xu", "authorId": "2308044030"}, {"name": "Tianyuan Shi", "authorId": "2308036711"}, {"name": "Zhengyuan Wang", "authorId": "2309182278"}, {"name": "Shizheng Li", "authorId": "2309656885"}, {"name": "Qi Qian", "authorId": "2309176521"}, {"name": "Ruicheng Yin", "authorId": "2292032843"}, {"name": "Changze Lv", "authorId": "2220896023"}, {"name": "Xiaoqing Zheng", "authorId": "2257315404"}, {"name": "Xuanjing Huang", "authorId": "2257129987"}], "n_citations": 61}, "snippets": ["Fine-tuning within the RAG framework is crucial for optimizing both retrievers and generators.Some research focuses on fine-tuning the generator to better utilize retriever context (Luo et al., 2023)[31][32], ensuring faithful and robust generated content.Others fine-tune the retriever to learn to retrieve beneficial passages for the generator [33][34][35].Holistic approaches treat RAG as an integrated system, fine-tuning both retriever and generator together to enhance overall performance [36][37][38], despite increased complexity and integration challenges."], "score": 0.9775390625}, {"id": "(Lin et al., 2023)", "paper": {"corpus_id": 263605962, "title": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning", "year": 2023, "venue": "International Conference on Learning Representations", "authors": [{"name": "Xi Victoria Lin", "authorId": "2255374957"}, {"name": "Xilun Chen", "authorId": "1769736"}, {"name": "Mingda Chen", "authorId": "46221498"}, {"name": "Weijia Shi", "authorId": "2254168373"}, {"name": "Maria Lomeli", "authorId": "2253400960"}, {"name": "Rich James", "authorId": "2191899140"}, {"name": "Pedro Rodriguez", "authorId": "2253404757"}, {"name": "Jacob Kahn", "authorId": "2253401183"}, {"name": "Gergely Szilvasy", "authorId": "2253402270"}, {"name": "Mike Lewis", "authorId": "2253417398"}, {"name": "Luke S. Zettlemoyer", "authorId": "2137813791"}, {"name": "Scott Yih", "authorId": "2253400757"}], "n_citations": 153}, "snippets": ["In this work, we show lightweight instruction tuning (Chung et al., 2022b;Iyer et al., 2022;Zhou et al., 2023) alone can significantly boost the performance of RALMs, especially in scenarios that require access to large, external knowledge sources. We propose Retrieval-Augmented Dual Instruction Tuning (RA-DIT), an approach that retrofits any LLM with retrieval capabilities via fine-tuning over a set of tasks selected to cultivate knowledge utilization and contextual awareness in the language model predictions", "RA-DIT updates the LLM with retrieval-augmented instruction tuning to make better use of retrieved knowledge and ignore irrelevant or distracting information. It also fine-tunes the retriever with supervision from the LLM to retrieve texts that can better help the LLM generate correct outputs. RA-DIT achieves state-of-the-art performance in zero-and few-shot evaluations on knowledge intensive benchmarks, surpassing un-tuned in-context RALM approaches such as REPLUG and compete effectively against methods that require extensive pre-training such as ATLAS."], "score": 0.96435546875}, {"id": "(Wang et al., 2025)", "paper": {"corpus_id": 278635834, "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "year": 2025, "venue": "", "authors": [{"name": "Shaohan Wang", "authorId": "2361597409"}, {"name": "L. Zhang", "authorId": "48378753"}, {"name": "Zheren Fu", "authorId": "2106681735"}, {"name": "Zhendong Mao", "authorId": "2349977855"}], "n_citations": 0}, "snippets": ["RA-DIT (Lin et al., 2023) uses modular training to optimize the retriever and LLM separately, enhancing overall RAG system performance."], "score": 0.9697265625}, {"id": "(Zhang et al., 2024)", "paper": {"corpus_id": 273969615, "title": "Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Zilun Zhang", "authorId": "2270181751"}, {"name": "Haozhan Shen", "authorId": "2174678931"}, {"name": "Tiancheng Zhao", "authorId": "8200875"}, {"name": "Yuhao Wang", "authorId": "2330774884"}, {"name": "Bin Chen", "authorId": "2330612748"}, {"name": "Yuxiang Cai", "authorId": "2149196373"}, {"name": "Yongheng Shang", "authorId": "2093090552"}, {"name": "Jianwei Yin", "authorId": "2111612160"}], "n_citations": 3}, "snippets": ["RA-DIT (Lin et al., 2023) uses dual instruction tuning to fine-tune the retriever and generative model, optimizing their collaboration for knowledgeintensive benchmarks."], "score": 0.9609375}, {"id": "(Yu et al., 2024)", "paper": {"corpus_id": 270878612, "title": "RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs", "year": 2024, "venue": "Neural Information Processing Systems", "authors": [{"name": "Yue Yu", "authorId": "2259265562"}, {"name": "Wei Ping", "authorId": "2253664013"}, {"name": "Zihan Liu", "authorId": "2256582287"}, {"name": "Boxin Wang", "authorId": "2256656241"}, {"name": "Jiaxuan You", "authorId": "2287859963"}, {"name": "Chao Zhang", "authorId": "2256776233"}, {"name": "M. Shoeybi", "authorId": "1911755"}, {"name": "Bryan Catanzaro", "authorId": "2264406909"}], "n_citations": 74}, "snippets": ["In this work, we propose a novel instruction fine-tuning framework RankRAG, which instruction-tunes a single LLM for the dual purpose of context ranking and answer generation in RAG. In particular, the instruction-tuned LLMs work surprisingly well by adding a small fraction of ranking data into the training blend, and outperform existing expert ranking models, including the same LLM exclusively fine-tuned on a large amount of ranking data."], "score": 0.9140625}, {"id": "(Gao et al., 2023)", "paper": {"corpus_id": 266359151, "title": "Retrieval-Augmented Generation for Large Language Models: A Survey", "year": 2023, "venue": "arXiv.org", "authors": [{"name": "Yunfan Gao", "authorId": "2280046531"}, {"name": "Yun Xiong", "authorId": "2275320371"}, {"name": "Xinyu Gao", "authorId": "2275341478"}, {"name": "Kangxiang Jia", "authorId": "2275191447"}, {"name": "Jinliu Pan", "authorId": "2275530552"}, {"name": "Yuxi Bi", "authorId": "2275171009"}, {"name": "Yi Dai", "authorId": "2276187454"}, {"name": "Jiawei Sun", "authorId": "2275540959"}, {"name": "Qianyu Guo", "authorId": "2258800561"}, {"name": "Meng Wang", "authorId": "2291409458"}, {"name": "Haofen Wang", "authorId": "2256769434"}], "n_citations": 1819}, "snippets": ["For example, this can involve fine-tuning the retriever for better retrieval results, fine-tuning the generator for more personalized outputs, or engaging in collaborative fine-tuning [27]", "A typical approach, such as RA-DIT [27], aligns the scoring functions between Retriever and Generator using KL divergence."], "score": 0.9228515625}, {"id": "(Gao et al., 2024)", "paper": {"corpus_id": 271571401, "title": "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Yunfan Gao", "authorId": "2280046531"}, {"name": "Yun Xiong", "authorId": "2275320371"}, {"name": "Meng Wang", "authorId": "2291409458"}, {"name": "Haofen Wang", "authorId": "2256769434"}], "n_citations": 20}, "snippets": ["Retriever Fine-tuning: In cases where the context may diverge from pre-trained corpus, particularly in highly specialized fields like healthcare, law, and other domains abundant in proprietary terminology. While this adjustment demands additional effort, it can substantially enhance retrieval efficiency and domain alignment.\n\nSupervised Fine-Tuning (SFT). Fine-tuning a retrieval model based on labeled domain data is typically done using contrastive learning. This involves reducing the distance between positive samples while increasing the distance between negative samples", ".3) Dual FT: In the RAG system, fine-tuning both the retriever and the generator simultaneously is a unique feature of the RAG system. It is important to note that the emphasis of system fine-tuning is on the coordination between the retriever and the generator. An exemplary implementation is RA-DIT [27], which fine-tunes both the LLM and the retriever. The LM-ft component updates the LLM to maximize the likelihood of the correct answer given the retrieval-augmented instructions while the R-ft component updates the retriever to minimize the KL-Divergence between the retriever score distribution and the LLM preference."], "score": 0.96435546875}, {"id": "(Peng et al., 2024)", "paper": {"corpus_id": 271903170, "title": "Graph Retrieval-Augmented Generation: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Boci Peng", "authorId": "2314827534"}, {"name": "Yun Zhu", "authorId": "2257195454"}, {"name": "Yongchao Liu", "authorId": "2313693489"}, {"name": "Xiaohe Bo", "authorId": "2316431106"}, {"name": "Haizhou Shi", "authorId": "2313685962"}, {"name": "Chuntao Hong", "authorId": "2313754922"}, {"name": "Yan Zhang", "authorId": "2316581992"}, {"name": "Siliang Tang", "authorId": "2257997261"}], "n_citations": 110}, "snippets": ["Joint training retrievers and generators simultaneously enhances performance on downstream tasks by leveraging their complementary strengths. Some approaches unify retrievers and generators into a single model, typically LLMs, and train them with both retrieval and generation objectives simultaneously [112]. This method capitalizes on the cohesive capabilities of a unified architecture, enabling the model to seamlessly retrieve relevant information and generate coherent responses within a single framework. \n\nOther methodologies involve initially training retrievers and generators separately, followed by joint training techniques to fine-tune both components. For instance, Subgraph Retriever [196] adopts an alternating training paradigm, where the retriever's parameters are fixed to use the graph data for training the generator. Subsequently, the generator's parameters are fixed, and feedback from the generator is used to guide the retriever's training. This iterative process helps both components refine their performance in a coordinated manner."], "score": 0.96044921875}, {"id": "(Zhang et al., 2025)", "paper": {"corpus_id": 276408682, "title": "Improving Retrieval-Augmented Deep Assertion Generation via Joint Training", "year": 2025, "venue": "IEEE Transactions on Software Engineering", "authors": [{"name": "Quanjun Zhang", "authorId": "1409701329"}, {"name": "Chunrong Fang", "authorId": "2239197945"}, {"name": "Yi Zheng", "authorId": "2346015117"}, {"name": "Ruixiang Qian", "authorId": "2133779426"}, {"name": "Shengcheng Yu", "authorId": "150311588"}, {"name": "Yuan Zhao", "authorId": "2285983793"}, {"name": "Jianyi Zhou", "authorId": "2296059777"}, {"name": "Yun Yang", "authorId": "2276454592"}, {"name": "Tao Zheng", "authorId": "2322486553"}, {"name": "Zhenyu Chen", "authorId": "2238950128"}], "n_citations": 1}, "snippets": ["The key insight of AG-RAG is to simultaneously optimize the retriever and the generator as a whole pipeline with a joint training strategy, enabling them to learn from each other. Particularly, AG-RAG builds a dense retriever to search for relevant test-assert pairs (TAPs) with semantic matching and a retrieval-augmented generator to synthesize accurate assertions with the focal-test and retrieved TAPs as input", "AG-RAG designs a joint training strategy that allows the retriever to learn from the feedback provided by the generator. This unified design fully adapts both components specifically for retrieving more useful TAPs, thereby generating accurate assertions."], "score": 0.939453125}, {"id": "(Hu et al., 2021)", "paper": {"corpus_id": 235458009, "title": "LoRA: Low-Rank Adaptation of Large Language Models", "year": 2021, "venue": "International Conference on Learning Representations", "authors": [{"name": "J. E. Hu", "authorId": "2157840220"}, {"name": "Yelong Shen", "authorId": "1752875"}, {"name": "Phillip Wallis", "authorId": "104100507"}, {"name": "Zeyuan Allen-Zhu", "authorId": "1388725932"}, {"name": "Yuanzhi Li", "authorId": "2110486765"}, {"name": "Shean Wang", "authorId": "2135571585"}, {"name": "Weizhu Chen", "authorId": "2109136147"}], "n_citations": 10511}, "snippets": ["An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA."], "score": 0.0}, {"id": "(Dettmers et al., 2023)", "paper": {"corpus_id": 258841328, "title": "QLoRA: Efficient Finetuning of Quantized LLMs", "year": 2023, "venue": "Neural Information Processing Systems", "authors": [{"name": "Tim Dettmers", "authorId": "3239480"}, {"name": "Artidoro Pagnoni", "authorId": "51152502"}, {"name": "Ari Holtzman", "authorId": "14487640"}, {"name": "Luke Zettlemoyer", "authorId": "1982950"}], "n_citations": 2606}, "snippets": ["We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training."], "score": 0.0}, {"id": "(Wu et al., 2024)", "paper": {"corpus_id": 271270644, "title": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Shangyu Wu", "authorId": "2112539433"}, {"name": "Ying Xiong", "authorId": "2303313918"}, {"name": "Yufei Cui", "authorId": "2301404967"}, {"name": "Haolun Wu", "authorId": "107747459"}, {"name": "Can Chen", "authorId": "2243412535"}, {"name": "Ye Yuan", "authorId": "2283264350"}, {"name": "Lianming Huang", "authorId": "2303518782"}, {"name": "Xue Liu", "authorId": "2272581493"}, {"name": "Tei-Wei Kuo", "authorId": "2271790635"}, {"name": "Nan Guan", "authorId": "2290008872"}, {"name": "C. Xue", "authorId": "2302177675"}], "n_citations": 39}, "snippets": ["As introduced in Section 6, RAG training includes two branch of works, RAG with/without datastore update. For RAG without datastore update, the main challenge is how to jointly optimize all parameters in RAG. This may involves new loss functions with multiple objectives, new optimizations for efficient tuning parameters in retriever and generator, or other training strategies. \n\nFor RAG with datastore update, one challenge is how to align the retrieval representations with the generator's representations. Although the time cost of the update operation in datastore cannot be ignored, some works (Chen et al., 2022) reduce the update frequency by asychronously updating, thus achieving the alignment of knowledge representation and model's representation. Another challenge is when to retrain/fine-tune the generator in RAG when new corpus is added. Due to the in-context learning capability of exisitng LLM-based generators and high training overhead, retraining/finetuning the generator or directly inferring the generator becomes a challenging choice for different scenarios. Recently, some efficient training strategies (Dettmers et al., 2023)(Hu et al., 2021) have been proposed to accelerate the fine-tuning process, which can be taken into considerations."], "score": 0.95166015625}, {"id": "(Chen et al., 2024)", "paper": {"corpus_id": 273695367, "title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Zhongwu Chen", "authorId": "2165306772"}, {"name": "Chengjin Xu", "authorId": "2250617116"}, {"name": "Dingmin Wang", "authorId": "2329140108"}, {"name": "Zhen Huang", "authorId": "2273614102"}, {"name": "Yong Dou", "authorId": "67069932"}, {"name": "Jian Guo", "authorId": "2284217200"}], "n_citations": 3}, "snippets": ["For rule-guided retriever fine-tuning (RGFT-retriever), we update the LM encoders in a contrastive learning objective (Chen et al., 2020) and train over supervised fine-tuning data F R provided in our constructed benchmarks, where inputs are the queries plus rules and supervised labels are heuristic oracle documents. Compared with retrievers employed with simple retrieval principles, our fine-tuned retrievers can recall more relevant results, aligned with the preferences of the rules. For rule-guided generator fine-tuning (RGFT-generator), we adopt the supervised instruction-tuning objective (Iyer et al., 2023;Chung et al., 2024) while combining each query q with two components: retrieved documents D q from the retrieval phase and the same set of rules R q consistent with the retrieval phase. The rules introduced in the RGFT-generator train LLMs on how to optimally attribute from the retrieved context into answers by following rules, making RuleRAG leverage the fine-tuned retrievers more rationally. Experiments show our proposed RGFT can further guarantee and boost the retrieval quality and answering accuracy of RuleRAG-FT than RuleRAG-ICL."], "score": 0.92236328125}, {"id": "(Chen et al., 2020)", "paper": {"corpus_id": 211096730, "title": "A Simple Framework for Contrastive Learning of Visual Representations", "year": 2020, "venue": "International Conference on Machine Learning", "authors": [{"name": "Ting Chen", "authorId": "145358498"}, {"name": "Simon Kornblith", "authorId": "40464924"}, {"name": "Mohammad Norouzi", "authorId": "144739074"}, {"name": "Geoffrey E. Hinton", "authorId": "1695689"}], "n_citations": 18878}, "snippets": ["This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels."], "score": 0.0}, {"id": "(Cheng et al., 2025)", "paper": {"corpus_id": 277043297, "title": "A Survey on Knowledge-Oriented Retrieval-Augmented Generation", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Mingyue Cheng", "authorId": "1491233507"}, {"name": "Yucong Luo", "authorId": "2208917508"}, {"name": "Ouyang Jie", "authorId": "2322501286"}, {"name": "Qi Liu", "authorId": "2332691115"}, {"name": "Huijie Liu", "authorId": "2312648865"}, {"name": "Li Li", "authorId": "2291070758"}, {"name": "Shuo Yu", "authorId": "2322429208"}, {"name": "Bohou Zhang", "authorId": "2351226328"}, {"name": "Jiawei Cao", "authorId": "2350426005"}, {"name": "Jie Ma", "authorId": "2350427710"}, {"name": "Daoyu Wang", "authorId": "2322524150"}, {"name": "Enhong Chen", "authorId": "2258714945"}], "n_citations": 6}, "snippets": ["Generator-Guided Retriever Training. Conversely, generator-guided retriever training focuses on optimizing the retriever based on the generator's performance and requirements. In this paradigm, the generator's ability to produce coherent and accurate text influences the retriever's selection process. DKRR [95] leverages the generator's attention scores to fine-tune the retriever, enhancing its capability to select the most pertinent information. AAR [272] employs smaller language models to generate supervision signals that guide the retriever's training, ensuring that the retrieved documents are optimally aligned with the generator's needs. RA-DIT [140] fine-tunes large language models before training the retriever, fostering better alignment and synergy between the two components. Additionally, UPRISE [33] uses a frozen LLM to guide the fine-tuning of a prompt retriever, thereby improving its effectiveness in retrieving data that the generator can utilize more effectively."], "score": 0.97412109375}, {"id": "(Shi et al., 2025)", "paper": {"corpus_id": 278339057, "title": "Direct Retrieval-augmented Optimization: Synergizing Knowledge Selection and Language Models", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Zhengliang Shi", "authorId": "2195381022"}, {"name": "Lingyong Yan", "authorId": "1387839383"}, {"name": "Weiwei Sun", "authorId": "2153198380"}, {"name": "Yue Feng", "authorId": "2326805997"}, {"name": "Pengjie Ren", "authorId": "1749477"}, {"name": "Xinyu Ma", "authorId": "2265517632"}, {"name": "Shuaiqiang Wang", "authorId": "2237948548"}, {"name": "Dawei Yin", "authorId": "2331316040"}, {"name": "M. D. Rijke", "authorId": "2265490493"}, {"name": "Zhaochun Ren", "authorId": "2261862546"}], "n_citations": 1}, "snippets": ["To optimize RAG performance, some studies improve knowledge accuracy by fine-tuning the retrieval or ranking model with relevance criteria [33,38,48]. Others enhance the robustness of LLMs against irrelevant content through supervised fine-tuning [10,71] or in-context learning [49], teaching them to summarize key points from retrieved documents. However, these approaches optimize either the selection or the generation component separately while neglecting a dual enhancement, which may lead to sub-optimal overall performance [27,45].\n\nTo address the above limitation, some recent studies train both the retriever and the LLM generator [23,25,51]", "Although existing work proposes the end-to-end training paradigm, they overly simplify a marginalization optimization through independent top-k approximation (Sachan et al., 2021)(Zamani et al., 2024), where they simply feed top-k documents into downstream LLMs one-by-one and re-score their relevance to optimize the retriever (Lewis et al., 2020)[27]. This has been criticized far from the practical scenarios as the RAG system typically consumes multiple documents (Zamani et al., 2024), while exhaustively enumerating all possible document permutations is cost-intensive and typically infeasible in practice."], "score": 0.96044921875}, {"id": "(Lewis et al., 2020)", "paper": {"corpus_id": 218869575, "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "year": 2020, "venue": "Neural Information Processing Systems", "authors": [{"name": "Patrick Lewis", "authorId": "145222654"}, {"name": "Ethan Perez", "authorId": "3439053"}, {"name": "Aleksandara Piktus", "authorId": "1716179427"}, {"name": "F. Petroni", "authorId": "40052301"}, {"name": "Vladimir Karpukhin", "authorId": "2067091563"}, {"name": "Naman Goyal", "authorId": "39589154"}, {"name": "Heinrich Kuttler", "authorId": "103131985"}, {"name": "M. Lewis", "authorId": "35084211"}, {"name": "Wen-tau Yih", "authorId": "144105277"}, {"name": "Tim Rockt\u00e4schel", "authorId": "2620211"}, {"name": "Sebastian Riedel", "authorId": "48662861"}, {"name": "Douwe Kiela", "authorId": "1743722"}], "n_citations": 6476}, "snippets": ["Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline."], "score": 0.0}, {"id": "(Zamani et al., 2024)", "paper": {"corpus_id": 269605438, "title": "Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization", "year": 2024, "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "authors": [{"name": "Hamed Zamani", "authorId": "2293725953"}, {"name": "Michael Bendersky", "authorId": "2240516450"}], "n_citations": 29}, "snippets": ["This paper introduces Stochastic RAG--a novel approach for end-to-end optimization of retrieval-augmented generation (RAG) models that relaxes the simplifying assumptions of marginalization and document independence, made in most prior work. Stochastic RAG casts the retrieval process in RAG as a stochastic sampling without replacement process. Through this formulation, we employ straight-through Gumbel-top-k that provides a differentiable approximation for sampling without replacement and enables effective end-to-end optimization for RAG. We conduct extensive experiments on seven diverse datasets on a wide range of tasks, from open-domain question answering to fact verification to slot-filling for relation extraction and to dialogue systems. By applying this optimization method to a recent and effective RAG model, we advance state-of-the-art results on six out of seven datasets."], "score": 0.0}, {"id": "(Fang et al., 2024)", "paper": {"corpus_id": 270199429, "title": "Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training", "year": 2024, "venue": "Annual Meeting of the Association for Computational Linguistics", "authors": [{"name": "Feiteng Fang", "authorId": "2293319089"}, {"name": "Yuelin Bai", "authorId": "2287892865"}, {"name": "Shiwen Ni", "authorId": "2266469238"}, {"name": "Min Yang", "authorId": "2301170603"}, {"name": "Xiaojun Chen", "authorId": "2287803799"}, {"name": "Ruifeng Xu", "authorId": "2266809482"}], "n_citations": 39}, "snippets": ["Large Language Models (LLMs) exhibit substantial capabilities yet encounter challenges, including hallucination, outdated knowledge, and untraceable reasoning processes. Retrieval-augmented generation (RAG) has emerged as a promising solution, integrating knowledge from external databases to mitigate these challenges. However, inappropriate retrieved passages can potentially hinder the LLMs' capacity to generate comprehensive and high-quality responses. Prior RAG studies on the robustness of retrieval noises often confine themselves to a limited set of noise types, deviating from real-world retrieval environments and limiting practical applicability. In this study, we initially investigate retrieval noises and categorize them into three distinct types, reflecting real-world environments. We analyze the impact of these various retrieval noises on the robustness of LLMs. Subsequently, we propose a novel RAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT). RAAT leverages adaptive adversarial training to dynamically adjust the model's training process in response to retrieval noises. Concurrently, it employs multi-task learning to ensure the model's capacity to internally recognize noisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model trained using RAAT exhibits significant improvements in F1 and EM scores under diverse noise conditions. For reproducibility, we release our code and data at: https://github.com/calubkk/RAAT."], "score": 0.0}], "table": null}, {"title": "Performance Comparison", "tldr": "Comparative studies reveal that dual fine-tuning approaches consistently outperform single-component fine-tuning across various knowledge-intensive tasks. RA-DIT demonstrates up to 8.9% improvement in zero-shot settings compared to non-tuned approaches, while methods addressing retrieval noise can prevent performance drops of up to 27% that occur with irrelevant document retrieval. (8 sources)", "text": "\n## Quantitative Performance Improvements\n\nDual fine-tuning approaches have demonstrated substantial performance advantages over methods that optimize only a single component of RAG systems. Retrieval-Augmented Dual Instruction Tuning (RA-DIT) has achieved state-of-the-art results on knowledge-intensive benchmarks, significantly outperforming non-tuned retrieval-augmented approaches like REPLUG in zero-shot evaluations <Paper corpusId=\"263605962\" paperTitle=\"(Lin et al., 2023)\" isShortName></Paper>. These improvements demonstrate the value of simultaneously optimizing both the retriever and generator components.\n\n## Robustness Against Retrieval Noise\n\nA critical advantage of dual fine-tuning approaches is their ability to mitigate the negative impact of noisy retrieval. Studies have shown that adding distracting or irrelevant documents to retrieved content can cause a dramatic 27% drop in accuracy on tasks like veracity classification <Paper corpusId=\"273185619\" paperTitle=\"(Sriram et al., 2024)\" isShortName></Paper> <Paper corpusId=\"250340232\" paperTitle=\"(Sauchuk et al., 2022)\" isShortName></Paper>. By training both components to work together, dual fine-tuning methods develop greater resilience to such retrieval noise, maintaining performance even when some retrieved information is irrelevant.\n\n## Comparative Analysis with Single-Component Approaches\n\nResearch comparing single-component and dual-component fine-tuning clearly demonstrates that optimizing either the retriever or generator in isolation leads to sub-optimal overall performance <Paper corpusId=\"278339057\" paperTitle=\"(Shi et al., 2025)\" isShortName></Paper>. While single-component approaches can address specific aspects of RAG performance\u2014such as improving knowledge accuracy through better retrieval or enhancing robustness against irrelevant content\u2014they fail to capture the interdependent nature of the retriever-generator relationship.\n\n## Practical Efficiency Considerations\n\nAlthough dual fine-tuning approaches achieve superior performance, they often involve implementation tradeoffs. Many existing methods employ independent top-k approximation, feeding top-k documents into language models one-by-one for relevance re-scoring <Paper corpusId=\"278339057\" paperTitle=\"(Shi et al., 2025)\" isShortName></Paper> <Paper corpusId=\"218869575\" paperTitle=\"(Lewis et al., 2020)\" isShortName></Paper>. This approach has been criticized as impractical since real-world RAG systems typically process multiple documents simultaneously, and exhaustively evaluating all possible document combinations is computationally infeasible <Paper corpusId=\"278339057\" paperTitle=\"(Shi et al., 2025)\" isShortName></Paper> <Paper corpusId=\"269605438\" paperTitle=\"(Zamani et al., 2024)\" isShortName></Paper>.\n\n## Real-World Reliability\n\nThe performance of dual fine-tuned RAG systems extends beyond benchmark scores to operational reliability. Research highlights that validation of RAG system performance is primarily feasible during actual operation, and robustness evolves rather than being designed in from the start <Paper corpusId=\"273185619\" paperTitle=\"(Sriram et al., 2024)\" isShortName></Paper> <Paper corpusId=\"266933076\" paperTitle=\"(Barnett et al., 2024)\" isShortName></Paper>. This perspective underscores the importance of dual fine-tuning approaches that can continue to improve through ongoing alignment of retriever and generator components.\n\n## Resilience Against Diverse Noise Types\n\nRecent advanced dual fine-tuning methods like Retrieval-augmented Adaptive Adversarial Training (RAAT) specifically address various types of retrieval noise that reflect real-world environments <Paper corpusId=\"270199429\" paperTitle=\"(Fang et al., 2024)\" isShortName></Paper>. These approaches employ adaptive adversarial training to dynamically adjust the model's training process in response to different noise types, resulting in significant improvements in performance metrics under diverse noise conditions.", "citations": [{"id": "(Lin et al., 2023)", "paper": {"corpus_id": 263605962, "title": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning", "year": 2023, "venue": "International Conference on Learning Representations", "authors": [{"name": "Xi Victoria Lin", "authorId": "2255374957"}, {"name": "Xilun Chen", "authorId": "1769736"}, {"name": "Mingda Chen", "authorId": "46221498"}, {"name": "Weijia Shi", "authorId": "2254168373"}, {"name": "Maria Lomeli", "authorId": "2253400960"}, {"name": "Rich James", "authorId": "2191899140"}, {"name": "Pedro Rodriguez", "authorId": "2253404757"}, {"name": "Jacob Kahn", "authorId": "2253401183"}, {"name": "Gergely Szilvasy", "authorId": "2253402270"}, {"name": "Mike Lewis", "authorId": "2253417398"}, {"name": "Luke S. Zettlemoyer", "authorId": "2137813791"}, {"name": "Scott Yih", "authorId": "2253400757"}], "n_citations": 153}, "snippets": ["In this work, we show lightweight instruction tuning (Chung et al., 2022b;Iyer et al., 2022;Zhou et al., 2023) alone can significantly boost the performance of RALMs, especially in scenarios that require access to large, external knowledge sources. We propose Retrieval-Augmented Dual Instruction Tuning (RA-DIT), an approach that retrofits any LLM with retrieval capabilities via fine-tuning over a set of tasks selected to cultivate knowledge utilization and contextual awareness in the language model predictions", "RA-DIT updates the LLM with retrieval-augmented instruction tuning to make better use of retrieved knowledge and ignore irrelevant or distracting information. It also fine-tunes the retriever with supervision from the LLM to retrieve texts that can better help the LLM generate correct outputs. RA-DIT achieves state-of-the-art performance in zero-and few-shot evaluations on knowledge intensive benchmarks, surpassing un-tuned in-context RALM approaches such as REPLUG and compete effectively against methods that require extensive pre-training such as ATLAS."], "score": 0.96435546875}, {"id": "(Sriram et al., 2024)", "paper": {"corpus_id": 273185619, "title": "Contrastive Learning to Improve Retrieval for Real-World Fact Checking", "year": 2024, "venue": "FEVER", "authors": [{"name": "Aniruddh Sriram", "authorId": "2165382262"}, {"name": "Fangyuan Xu", "authorId": "2159829626"}, {"name": "Eunsol Choi", "authorId": "2257003422"}, {"name": "Greg Durrett", "authorId": "1814094"}], "n_citations": 1}, "snippets": ["Retrieval-augmented generation (RAG) relies on two key modules: a retriever and a reader/generation model. For many RAG systems, noisy retrieval hurts downstream performance by providing irrelevant or misleading documents (Yoran et al., 2024). (Sauchuk et al., 2022) found that adding distractors can cause a 27% drop on veracity classification accuracy on FEVER. Therefore, it's important for retrievers to find relevant documents and simultaneously avoid damaging ones. Shi et al. (2023) attempts to solve this problem by finetuning the retrieval component while fixing the reader LM, similar to our work. Other approaches like Ke et al. (2024) create a more complex system with a \"bridging\" model between the retriever and reader. Nevertheless, noisy retrieval remains a failure point in RAG systems (Barnett et al., 2024), and tangible downstream gains can be realized by further finetuning."], "score": 0.91357421875}, {"id": "(Sauchuk et al., 2022)", "paper": {"corpus_id": 250340232, "title": "On the Role of Relevance in Natural Language Processing Tasks", "year": 2022, "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "authors": [{"name": "Artsiom Sauchuk", "authorId": "2175275805"}, {"name": "James Thorne", "authorId": "2053211210"}, {"name": "A. Halevy", "authorId": "1770962"}, {"name": "N. Tonellotto", "authorId": "2783910"}, {"name": "F. Silvestri", "authorId": "144925193"}], "n_citations": 16}, "snippets": ["Many recent Natural Language Processing (NLP) task formulations, such as question answering and fact verification, are implemented as a two-stage cascading architecture. In the first stage an IR system retrieves \"relevant'' documents containing the knowledge, and in the second stage an NLP system performs reasoning to solve the task. Optimizing the IR system for retrieving relevant documents ensures that the NLP system has sufficient information to operate over. These recent NLP task formulations raise interesting and exciting challenges for IR, where the end-user of an IR system is not a human with an information need, but another system exploiting the documents retrieved by the IR system to perform reasoning and address the user information need. Among these challenges, as we will show, is that noise from the IR system, such as retrieving spurious or irrelevant documents, can negatively impact the accuracy of the downstream reasoning module. Hence, there is the need to balance maximizing relevance while minimizing noise in the IR system. This paper presents experimental results on two NLP tasks implemented as a two-stage cascading architecture. We show how spurious or irrelevant retrieved results from the first stage can induce errors in the second stage. We use these results to ground our discussion of the research challenges that the IR community should address in the context of these knowledge-intensive NLP tasks."], "score": 0.0}, {"id": "(Shi et al., 2025)", "paper": {"corpus_id": 278339057, "title": "Direct Retrieval-augmented Optimization: Synergizing Knowledge Selection and Language Models", "year": 2025, "venue": "arXiv.org", "authors": [{"name": "Zhengliang Shi", "authorId": "2195381022"}, {"name": "Lingyong Yan", "authorId": "1387839383"}, {"name": "Weiwei Sun", "authorId": "2153198380"}, {"name": "Yue Feng", "authorId": "2326805997"}, {"name": "Pengjie Ren", "authorId": "1749477"}, {"name": "Xinyu Ma", "authorId": "2265517632"}, {"name": "Shuaiqiang Wang", "authorId": "2237948548"}, {"name": "Dawei Yin", "authorId": "2331316040"}, {"name": "M. D. Rijke", "authorId": "2265490493"}, {"name": "Zhaochun Ren", "authorId": "2261862546"}], "n_citations": 1}, "snippets": ["To optimize RAG performance, some studies improve knowledge accuracy by fine-tuning the retrieval or ranking model with relevance criteria [33,38,48]. Others enhance the robustness of LLMs against irrelevant content through supervised fine-tuning [10,71] or in-context learning [49], teaching them to summarize key points from retrieved documents. However, these approaches optimize either the selection or the generation component separately while neglecting a dual enhancement, which may lead to sub-optimal overall performance [27,45].\n\nTo address the above limitation, some recent studies train both the retriever and the LLM generator [23,25,51]", "Although existing work proposes the end-to-end training paradigm, they overly simplify a marginalization optimization through independent top-k approximation (Sachan et al., 2021)(Zamani et al., 2024), where they simply feed top-k documents into downstream LLMs one-by-one and re-score their relevance to optimize the retriever (Lewis et al., 2020)[27]. This has been criticized far from the practical scenarios as the RAG system typically consumes multiple documents (Zamani et al., 2024), while exhaustively enumerating all possible document permutations is cost-intensive and typically infeasible in practice."], "score": 0.96044921875}, {"id": "(Lewis et al., 2020)", "paper": {"corpus_id": 218869575, "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "year": 2020, "venue": "Neural Information Processing Systems", "authors": [{"name": "Patrick Lewis", "authorId": "145222654"}, {"name": "Ethan Perez", "authorId": "3439053"}, {"name": "Aleksandara Piktus", "authorId": "1716179427"}, {"name": "F. Petroni", "authorId": "40052301"}, {"name": "Vladimir Karpukhin", "authorId": "2067091563"}, {"name": "Naman Goyal", "authorId": "39589154"}, {"name": "Heinrich Kuttler", "authorId": "103131985"}, {"name": "M. Lewis", "authorId": "35084211"}, {"name": "Wen-tau Yih", "authorId": "144105277"}, {"name": "Tim Rockt\u00e4schel", "authorId": "2620211"}, {"name": "Sebastian Riedel", "authorId": "48662861"}, {"name": "Douwe Kiela", "authorId": "1743722"}], "n_citations": 6476}, "snippets": ["Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline."], "score": 0.0}, {"id": "(Zamani et al., 2024)", "paper": {"corpus_id": 269605438, "title": "Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization", "year": 2024, "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "authors": [{"name": "Hamed Zamani", "authorId": "2293725953"}, {"name": "Michael Bendersky", "authorId": "2240516450"}], "n_citations": 29}, "snippets": ["This paper introduces Stochastic RAG--a novel approach for end-to-end optimization of retrieval-augmented generation (RAG) models that relaxes the simplifying assumptions of marginalization and document independence, made in most prior work. Stochastic RAG casts the retrieval process in RAG as a stochastic sampling without replacement process. Through this formulation, we employ straight-through Gumbel-top-k that provides a differentiable approximation for sampling without replacement and enables effective end-to-end optimization for RAG. We conduct extensive experiments on seven diverse datasets on a wide range of tasks, from open-domain question answering to fact verification to slot-filling for relation extraction and to dialogue systems. By applying this optimization method to a recent and effective RAG model, we advance state-of-the-art results on six out of seven datasets."], "score": 0.0}, {"id": "(Barnett et al., 2024)", "paper": {"corpus_id": 266933076, "title": "Seven Failure Points When Engineering a Retrieval Augmented Generation System", "year": 2024, "venue": "2024 IEEE/ACM 3rd International Conference on AI Engineering \u2013 Software Engineering for AI (CAIN)", "authors": [{"name": "Scott Barnett", "authorId": "2052845461"}, {"name": "Stefanus Kurniawan", "authorId": "2266469333"}, {"name": "Srikanth Thudumu", "authorId": "2257020336"}, {"name": "Zach Brannelly", "authorId": "2279020735"}, {"name": "Mohamed Abdelrazek", "authorId": "47505933"}], "n_citations": 92}, "snippets": ["Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.CCS CONCEPTS\u2022 Software and its engineering \u2192 Empirical software validation."], "score": 0.0}, {"id": "(Fang et al., 2024)", "paper": {"corpus_id": 270199429, "title": "Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training", "year": 2024, "venue": "Annual Meeting of the Association for Computational Linguistics", "authors": [{"name": "Feiteng Fang", "authorId": "2293319089"}, {"name": "Yuelin Bai", "authorId": "2287892865"}, {"name": "Shiwen Ni", "authorId": "2266469238"}, {"name": "Min Yang", "authorId": "2301170603"}, {"name": "Xiaojun Chen", "authorId": "2287803799"}, {"name": "Ruifeng Xu", "authorId": "2266809482"}], "n_citations": 39}, "snippets": ["Large Language Models (LLMs) exhibit substantial capabilities yet encounter challenges, including hallucination, outdated knowledge, and untraceable reasoning processes. Retrieval-augmented generation (RAG) has emerged as a promising solution, integrating knowledge from external databases to mitigate these challenges. However, inappropriate retrieved passages can potentially hinder the LLMs' capacity to generate comprehensive and high-quality responses. Prior RAG studies on the robustness of retrieval noises often confine themselves to a limited set of noise types, deviating from real-world retrieval environments and limiting practical applicability. In this study, we initially investigate retrieval noises and categorize them into three distinct types, reflecting real-world environments. We analyze the impact of these various retrieval noises on the robustness of LLMs. Subsequently, we propose a novel RAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT). RAAT leverages adaptive adversarial training to dynamically adjust the model's training process in response to retrieval noises. Concurrently, it employs multi-task learning to ensure the model's capacity to internally recognize noisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model trained using RAAT exhibits significant improvements in F1 and EM scores under diverse noise conditions. For reproducibility, we release our code and data at: https://github.com/calubkk/RAAT."], "score": 0.0}], "table": null}, {"title": "Challenges and Future Directions", "tldr": "RAG systems face significant challenges in efficiently optimizing both retriever and generator components simultaneously, which requires innovative loss functions and parameter-efficient methods. Future research directions include developing better alignment techniques between retrieval representations and generator needs, along with more efficient fine-tuning strategies that balance computational constraints with performance. (5 sources)", "text": "\n## Computational Efficiency Challenges\n\nOne of the primary challenges in RAG optimization is the computational burden of jointly fine-tuning both the retriever and generator components. As language models continue to grow in size, traditional full fine-tuning approaches become increasingly impractical <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper>. This has spurred the development of parameter-efficient tuning methods like Low-Rank Adaptation (LoRA), which freezes pre-trained model weights and injects trainable rank decomposition matrices into each Transformer layer, reducing the number of trainable parameters by up to 10,000 times compared to full fine-tuning of large models <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper> <Paper corpusId=\"235458009\" paperTitle=\"(Hu et al., 2021)\" isShortName></Paper>.\n\nBuilding on this approach, QLoRA has further improved efficiency by enabling the fine-tuning of 65B parameter models on a single GPU through 4-bit quantization techniques while maintaining performance comparable to full 16-bit fine-tuning <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper> <Paper corpusId=\"258841328\" paperTitle=\"(Dettmers et al., 2023)\" isShortName></Paper>. These advances are crucial for making dual fine-tuning approaches more accessible and practical.\n\n## Knowledge Representation Alignment\n\nAnother significant challenge involves aligning retrieval representations with the generator's knowledge representation needs. In systems that update their datastores, this alignment becomes particularly important for ensuring that retrieved content is maximally useful for the generator <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper>. Some approaches have addressed this through asynchronous updating of datastores, which reduces update frequency while still achieving representation alignment <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper> <Paper corpusId=\"249191271\" paperTitle=\"(Chen et al., 2022)\" isShortName></Paper>.\n\n## Generator Update Frequency\n\nA practical consideration for RAG deployment is determining when to retrain or fine-tune the generator component when new content is added to the corpus. Given the high computational cost of model fine-tuning versus the in-context learning capabilities of modern LLMs, this presents a challenging tradeoff <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper>. The development of more efficient fine-tuning strategies offers promising solutions to this challenge, potentially allowing for more frequent updates without prohibitive computational costs.\n\n## Future Research Directions\n\nResearch is increasingly moving toward joint optimization approaches that can simultaneously improve both components of RAG systems. Future work will likely focus on developing new loss functions with multiple objectives and novel optimization strategies for efficient parameter tuning <Paper corpusId=\"271270644\" paperTitle=\"(Wu et al., 2024)\" isShortName></Paper>.\n\nOne promising direction involves combining fine-tuning of the generator with learned retrieval mechanisms such as reranker-aware retrievers or contrastively trained retrievers, which could further enhance factual accuracy and context filtering capabilities <Paper corpusId=\"278714952\" paperTitle=\"(Lee et al., 2025)\" isShortName></Paper>. This integrated approach acknowledges the interdependent nature of retrieval and generation in RAG systems and seeks to optimize their interaction rather than treating them as separate components.\n\nAs the field advances, we may also see more sophisticated techniques for dynamically adjusting the balance between parametric knowledge (stored in model weights) and non-parametric knowledge (accessed through retrieval). This could potentially lead to more adaptable RAG systems that can efficiently incorporate new information while maintaining robust performance on established knowledge domains <Model name=\"Anthropic\" version=\"claude-3-7-sonnet-20250219\">.", "citations": [{"id": "(Wu et al., 2024)", "paper": {"corpus_id": 271270644, "title": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "year": 2024, "venue": "arXiv.org", "authors": [{"name": "Shangyu Wu", "authorId": "2112539433"}, {"name": "Ying Xiong", "authorId": "2303313918"}, {"name": "Yufei Cui", "authorId": "2301404967"}, {"name": "Haolun Wu", "authorId": "107747459"}, {"name": "Can Chen", "authorId": "2243412535"}, {"name": "Ye Yuan", "authorId": "2283264350"}, {"name": "Lianming Huang", "authorId": "2303518782"}, {"name": "Xue Liu", "authorId": "2272581493"}, {"name": "Tei-Wei Kuo", "authorId": "2271790635"}, {"name": "Nan Guan", "authorId": "2290008872"}, {"name": "C. Xue", "authorId": "2302177675"}], "n_citations": 39}, "snippets": ["As introduced in Section 6, RAG training includes two branch of works, RAG with/without datastore update. For RAG without datastore update, the main challenge is how to jointly optimize all parameters in RAG. This may involves new loss functions with multiple objectives, new optimizations for efficient tuning parameters in retriever and generator, or other training strategies. \n\nFor RAG with datastore update, one challenge is how to align the retrieval representations with the generator's representations. Although the time cost of the update operation in datastore cannot be ignored, some works (Chen et al., 2022) reduce the update frequency by asychronously updating, thus achieving the alignment of knowledge representation and model's representation. Another challenge is when to retrain/fine-tune the generator in RAG when new corpus is added. Due to the in-context learning capability of exisitng LLM-based generators and high training overhead, retraining/finetuning the generator or directly inferring the generator becomes a challenging choice for different scenarios. Recently, some efficient training strategies (Dettmers et al., 2023)(Hu et al., 2021) have been proposed to accelerate the fine-tuning process, which can be taken into considerations."], "score": 0.95166015625}, {"id": "(Hu et al., 2021)", "paper": {"corpus_id": 235458009, "title": "LoRA: Low-Rank Adaptation of Large Language Models", "year": 2021, "venue": "International Conference on Learning Representations", "authors": [{"name": "J. E. Hu", "authorId": "2157840220"}, {"name": "Yelong Shen", "authorId": "1752875"}, {"name": "Phillip Wallis", "authorId": "104100507"}, {"name": "Zeyuan Allen-Zhu", "authorId": "1388725932"}, {"name": "Yuanzhi Li", "authorId": "2110486765"}, {"name": "Shean Wang", "authorId": "2135571585"}, {"name": "Weizhu Chen", "authorId": "2109136147"}], "n_citations": 10511}, "snippets": ["An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA."], "score": 0.0}, {"id": "(Dettmers et al., 2023)", "paper": {"corpus_id": 258841328, "title": "QLoRA: Efficient Finetuning of Quantized LLMs", "year": 2023, "venue": "Neural Information Processing Systems", "authors": [{"name": "Tim Dettmers", "authorId": "3239480"}, {"name": "Artidoro Pagnoni", "authorId": "51152502"}, {"name": "Ari Holtzman", "authorId": "14487640"}, {"name": "Luke Zettlemoyer", "authorId": "1982950"}], "n_citations": 2606}, "snippets": ["We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training."], "score": 0.0}, {"id": "(Chen et al., 2022)", "paper": {"corpus_id": 249191271, "title": "Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning", "year": 2022, "venue": "Neural Information Processing Systems", "authors": [{"name": "Xiang Chen", "authorId": null}, {"name": "Lei Li", "authorId": null}, {"name": "Ningyu Zhang", "authorId": "2153010067"}, {"name": "Xiaozhuan Liang", "authorId": "2153398295"}, {"name": "Shumin Deng", "authorId": "152931849"}, {"name": "Chuanqi Tan", "authorId": "2111727840"}, {"name": "Fei Huang", "authorId": "2087380523"}, {"name": "Luo Si", "authorId": "2059080424"}, {"name": "Huajun Chen", "authorId": "49178307"}], "n_citations": 54}, "snippets": ["Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop RetroPrompt with the motivation of decoupling knowledge from memorization to help the model strike a balance between generalization and memorization. In contrast with vanilla prompt learning, RetroPrompt constructs an open-book knowledge-store from training instances and implements a retrieval mechanism during the process of input, training and inference, thus equipping the model with the ability to retrieve related contexts from the training corpus as cues for enhancement. Extensive experiments demonstrate that RetroPrompt can obtain better performance in both few-shot and zero-shot settings. Besides, we further illustrate that our proposed RetroPrompt can yield better generalization abilities with new datasets. Detailed analysis of memorization indeed reveals RetroPrompt can reduce the reliance of language models on memorization; thus, improving generalization for downstream tasks. Code is available in https://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt."], "score": 0.0}, {"id": "(Lee et al., 2025)", "paper": {"corpus_id": 278714952, "title": "Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation", "year": 2025, "venue": "", "authors": [{"name": "Zhan Peng Lee", "authorId": "2362089035"}, {"name": "Andre Lin", "authorId": "2362188632"}, {"name": "Calvin Tan", "authorId": "2363425126"}], "n_citations": 0}, "snippets": ["\u2022 Joint retrieval-generation optimization: While Finetune-RAG focuses on improving the generation component, combining it with learned retrieval mechanisms such as rerankeraware retrievers or contrastively trained retrievers could lead to further improvements in factual accuracy and context filtering."], "score": 0.90966796875}], "table": null}], "cost": 0.38316900000000004}}
