{"reformulated1": "What specific cultural biases and language artifacts are introduced when translating English evaluation benchmarks into non-English languages, and how do they impact model performance and reliability assessments?", "reformulated2": "What best practices and quality assurance measures are recommended to improve the linguistic naturalness and cross-lingual consistency of translation-based multilingual evaluation datasets, especially in low-resource languages?", "reformulated3": "How do evaluation results and human judgment correlations differ between translation-based multilingual datasets and datasets natively constructed in the target language or region, and what are the implications for cross-lingual benchmark design?"}
